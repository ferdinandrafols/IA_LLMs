{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMn2Xj0JMyJJqSObB8Ot7I1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdinandrafols/IA_LLMs/blob/main/GSI073_aula0_redes_neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GSI073 - Tópicos Especiais de Inteligência Artificial\n",
        "\n",
        "Definição dos dados"
      ],
      "metadata": {
        "id": "mT7pX0LDgoqx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhtiC6mtgUOS",
        "outputId": "2d6fba01-0bcd-4317-ce3b-9740748a8296"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variável X (features):\n",
            "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
            "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
            "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
            "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
            "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
            "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
            "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
            "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
            "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
            "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
            "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
            "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
            "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
            "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
            "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
            "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
            "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
            "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
            "        [5.1000, 3.8000, 1.5000, 0.3000],\n",
            "        [5.4000, 3.4000, 1.7000, 0.2000],\n",
            "        [5.1000, 3.7000, 1.5000, 0.4000],\n",
            "        [4.6000, 3.6000, 1.0000, 0.2000],\n",
            "        [5.1000, 3.3000, 1.7000, 0.5000],\n",
            "        [4.8000, 3.4000, 1.9000, 0.2000],\n",
            "        [5.0000, 3.0000, 1.6000, 0.2000],\n",
            "        [5.0000, 3.4000, 1.6000, 0.4000],\n",
            "        [5.2000, 3.5000, 1.5000, 0.2000],\n",
            "        [5.2000, 3.4000, 1.4000, 0.2000],\n",
            "        [4.7000, 3.2000, 1.6000, 0.2000],\n",
            "        [4.8000, 3.1000, 1.6000, 0.2000],\n",
            "        [5.4000, 3.4000, 1.5000, 0.4000],\n",
            "        [5.2000, 4.1000, 1.5000, 0.1000],\n",
            "        [5.5000, 4.2000, 1.4000, 0.2000],\n",
            "        [4.9000, 3.1000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.2000, 1.2000, 0.2000],\n",
            "        [5.5000, 3.5000, 1.3000, 0.2000],\n",
            "        [4.9000, 3.6000, 1.4000, 0.1000],\n",
            "        [4.4000, 3.0000, 1.3000, 0.2000],\n",
            "        [5.1000, 3.4000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.5000, 1.3000, 0.3000],\n",
            "        [4.5000, 2.3000, 1.3000, 0.3000],\n",
            "        [4.4000, 3.2000, 1.3000, 0.2000],\n",
            "        [5.0000, 3.5000, 1.6000, 0.6000],\n",
            "        [5.1000, 3.8000, 1.9000, 0.4000],\n",
            "        [4.8000, 3.0000, 1.4000, 0.3000],\n",
            "        [5.1000, 3.8000, 1.6000, 0.2000],\n",
            "        [4.6000, 3.2000, 1.4000, 0.2000],\n",
            "        [5.3000, 3.7000, 1.5000, 0.2000],\n",
            "        [5.0000, 3.3000, 1.4000, 0.2000],\n",
            "        [7.0000, 3.2000, 4.7000, 1.4000],\n",
            "        [6.4000, 3.2000, 4.5000, 1.5000],\n",
            "        [6.9000, 3.1000, 4.9000, 1.5000],\n",
            "        [5.5000, 2.3000, 4.0000, 1.3000],\n",
            "        [6.5000, 2.8000, 4.6000, 1.5000],\n",
            "        [5.7000, 2.8000, 4.5000, 1.3000],\n",
            "        [6.3000, 3.3000, 4.7000, 1.6000],\n",
            "        [4.9000, 2.4000, 3.3000, 1.0000],\n",
            "        [6.6000, 2.9000, 4.6000, 1.3000],\n",
            "        [5.2000, 2.7000, 3.9000, 1.4000],\n",
            "        [5.0000, 2.0000, 3.5000, 1.0000],\n",
            "        [5.9000, 3.0000, 4.2000, 1.5000],\n",
            "        [6.0000, 2.2000, 4.0000, 1.0000],\n",
            "        [6.1000, 2.9000, 4.7000, 1.4000],\n",
            "        [5.6000, 2.9000, 3.6000, 1.3000],\n",
            "        [6.7000, 3.1000, 4.4000, 1.4000],\n",
            "        [5.6000, 3.0000, 4.5000, 1.5000],\n",
            "        [5.8000, 2.7000, 4.1000, 1.0000],\n",
            "        [6.2000, 2.2000, 4.5000, 1.5000],\n",
            "        [5.6000, 2.5000, 3.9000, 1.1000],\n",
            "        [5.9000, 3.2000, 4.8000, 1.8000],\n",
            "        [6.1000, 2.8000, 4.0000, 1.3000],\n",
            "        [6.3000, 2.5000, 4.9000, 1.5000],\n",
            "        [6.1000, 2.8000, 4.7000, 1.2000],\n",
            "        [6.4000, 2.9000, 4.3000, 1.3000],\n",
            "        [6.6000, 3.0000, 4.4000, 1.4000],\n",
            "        [6.8000, 2.8000, 4.8000, 1.4000],\n",
            "        [6.7000, 3.0000, 5.0000, 1.7000],\n",
            "        [6.0000, 2.9000, 4.5000, 1.5000],\n",
            "        [5.7000, 2.6000, 3.5000, 1.0000],\n",
            "        [5.5000, 2.4000, 3.8000, 1.1000],\n",
            "        [5.5000, 2.4000, 3.7000, 1.0000],\n",
            "        [5.8000, 2.7000, 3.9000, 1.2000],\n",
            "        [6.0000, 2.7000, 5.1000, 1.6000],\n",
            "        [5.4000, 3.0000, 4.5000, 1.5000],\n",
            "        [6.0000, 3.4000, 4.5000, 1.6000],\n",
            "        [6.7000, 3.1000, 4.7000, 1.5000],\n",
            "        [6.3000, 2.3000, 4.4000, 1.3000],\n",
            "        [5.6000, 3.0000, 4.1000, 1.3000],\n",
            "        [5.5000, 2.5000, 4.0000, 1.3000],\n",
            "        [5.5000, 2.6000, 4.4000, 1.2000],\n",
            "        [6.1000, 3.0000, 4.6000, 1.4000],\n",
            "        [5.8000, 2.6000, 4.0000, 1.2000],\n",
            "        [5.0000, 2.3000, 3.3000, 1.0000],\n",
            "        [5.6000, 2.7000, 4.2000, 1.3000],\n",
            "        [5.7000, 3.0000, 4.2000, 1.2000],\n",
            "        [5.7000, 2.9000, 4.2000, 1.3000],\n",
            "        [6.2000, 2.9000, 4.3000, 1.3000],\n",
            "        [5.1000, 2.5000, 3.0000, 1.1000],\n",
            "        [5.7000, 2.8000, 4.1000, 1.3000],\n",
            "        [6.3000, 3.3000, 6.0000, 2.5000],\n",
            "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
            "        [7.1000, 3.0000, 5.9000, 2.1000],\n",
            "        [6.3000, 2.9000, 5.6000, 1.8000],\n",
            "        [6.5000, 3.0000, 5.8000, 2.2000],\n",
            "        [7.6000, 3.0000, 6.6000, 2.1000],\n",
            "        [4.9000, 2.5000, 4.5000, 1.7000],\n",
            "        [7.3000, 2.9000, 6.3000, 1.8000],\n",
            "        [6.7000, 2.5000, 5.8000, 1.8000],\n",
            "        [7.2000, 3.6000, 6.1000, 2.5000],\n",
            "        [6.5000, 3.2000, 5.1000, 2.0000],\n",
            "        [6.4000, 2.7000, 5.3000, 1.9000],\n",
            "        [6.8000, 3.0000, 5.5000, 2.1000],\n",
            "        [5.7000, 2.5000, 5.0000, 2.0000],\n",
            "        [5.8000, 2.8000, 5.1000, 2.4000],\n",
            "        [6.4000, 3.2000, 5.3000, 2.3000],\n",
            "        [6.5000, 3.0000, 5.5000, 1.8000],\n",
            "        [7.7000, 3.8000, 6.7000, 2.2000],\n",
            "        [7.7000, 2.6000, 6.9000, 2.3000],\n",
            "        [6.0000, 2.2000, 5.0000, 1.5000],\n",
            "        [6.9000, 3.2000, 5.7000, 2.3000],\n",
            "        [5.6000, 2.8000, 4.9000, 2.0000],\n",
            "        [7.7000, 2.8000, 6.7000, 2.0000],\n",
            "        [6.3000, 2.7000, 4.9000, 1.8000],\n",
            "        [6.7000, 3.3000, 5.7000, 2.1000],\n",
            "        [7.2000, 3.2000, 6.0000, 1.8000],\n",
            "        [6.2000, 2.8000, 4.8000, 1.8000],\n",
            "        [6.1000, 3.0000, 4.9000, 1.8000],\n",
            "        [6.4000, 2.8000, 5.6000, 2.1000],\n",
            "        [7.2000, 3.0000, 5.8000, 1.6000],\n",
            "        [7.4000, 2.8000, 6.1000, 1.9000],\n",
            "        [7.9000, 3.8000, 6.4000, 2.0000],\n",
            "        [6.4000, 2.8000, 5.6000, 2.2000],\n",
            "        [6.3000, 2.8000, 5.1000, 1.5000],\n",
            "        [6.1000, 2.6000, 5.6000, 1.4000],\n",
            "        [7.7000, 3.0000, 6.1000, 2.3000],\n",
            "        [6.3000, 3.4000, 5.6000, 2.4000],\n",
            "        [6.4000, 3.1000, 5.5000, 1.8000],\n",
            "        [6.0000, 3.0000, 4.8000, 1.8000],\n",
            "        [6.9000, 3.1000, 5.4000, 2.1000],\n",
            "        [6.7000, 3.1000, 5.6000, 2.4000],\n",
            "        [6.9000, 3.1000, 5.1000, 2.3000],\n",
            "        [5.8000, 2.7000, 5.1000, 1.9000],\n",
            "        [6.8000, 3.2000, 5.9000, 2.3000],\n",
            "        [6.7000, 3.3000, 5.7000, 2.5000],\n",
            "        [6.7000, 3.0000, 5.2000, 2.3000],\n",
            "        [6.3000, 2.5000, 5.0000, 1.9000],\n",
            "        [6.5000, 3.0000, 5.2000, 2.0000],\n",
            "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
            "        [5.9000, 3.0000, 5.1000, 1.8000]])\n",
            "\n",
            "Variável y (target):\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "import torch; import sklearn; from torch import nn\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Adicionar print para ver o resultado\n",
        "print(\"Variável X (features):\")\n",
        "print(X)\n",
        "print(\"\\nVariável y (target):\")\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos interpretar o que você está vendo.\n",
        "\n",
        "---\n",
        "\n",
        "## 1. O que é o **X** (features)\n",
        "\n",
        "Trecho do início de `X`:\n",
        "\n",
        "```text\n",
        "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
        "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
        "        ...\n",
        "```\n",
        "\n",
        "Isso significa:\n",
        "\n",
        "* `X` é um tensor de shape **[150, 4]** (150 linhas, 4 colunas).\n",
        "* Cada **linha** = 1 flor (1 observação do dataset Iris).\n",
        "* Cada **coluna** = 1 característica (*feature*):\n",
        "\n",
        "  1. comprimento da sépala\n",
        "  2. largura da sépala\n",
        "  3. comprimento da pétala\n",
        "  4. largura da pétala\n",
        "\n",
        "Então, por exemplo:\n",
        "\n",
        "```text\n",
        "[5.1000, 3.5000, 1.4000, 0.2000]\n",
        "```\n",
        "\n",
        "→ é uma flor com:\n",
        "\n",
        "* sépala 5.1 × 3.5\n",
        "* pétala 1.4 × 0.2\n",
        "\n",
        "As primeiras 50 linhas, como você vê pelos números pequenos de pétala (≈ 1.x), são da classe **Setosa**.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. O que é o **y** (target binário)\n",
        "\n",
        "Trecho do início de `y`:\n",
        "\n",
        "```text\n",
        "tensor([[0.],\n",
        "        [0.],\n",
        "        [0.],\n",
        "        ...\n",
        "        [0.],\n",
        "        [0.],\n",
        "        [0.],\n",
        "        [1.],\n",
        "        [1.],\n",
        "        [1.],\n",
        "        ...\n",
        "        [1.],\n",
        "        [1.],\n",
        "        [0.],\n",
        "        [0.],\n",
        "        ...\n",
        "```\n",
        "\n",
        "Aqui está a mágica:\n",
        "\n",
        "Você definiu:\n",
        "\n",
        "```python\n",
        "y = (iris.target == 1).astype(float)\n",
        "```\n",
        "\n",
        "Isso transforma o problema em **classificação binária**:\n",
        "\n",
        "* `1.0` → a flor é **Versicolor** (classe 1 no Iris)\n",
        "* `0.0` → a flor **não é Versicolor** (ou seja, é Setosa (0) ou Virginica (2))\n",
        "\n",
        "O padrão do Iris é:\n",
        "\n",
        "* amostras 0–49 → Setosa (classe 0) → viram `0.`\n",
        "* amostras 50–99 → Versicolor (classe 1) → viram `1.`\n",
        "* amostras 100–149 → Virginica (classe 2) → viram `0.`\n",
        "\n",
        "E é exatamente isso que o seu `y` mostra:\n",
        "\n",
        "* um bloco grande de **0.** no começo (Setosa) ✅\n",
        "* um bloco de **1.** no meio (Versicolor) ✅\n",
        "* um bloco de **0.** no final (Virginica) ✅\n",
        "\n",
        "Ou seja: o *target* está correto para a tarefa\n",
        "\n",
        "> “prever se a flor é Versicolor (1) ou não (0)”.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Estrutura está perfeita pra ML / PyTorch\n",
        "\n",
        "Você agora tem:\n",
        "\n",
        "* `X`: `torch.Size([150, 4])`, `dtype=torch.float32`\n",
        "* `y`: `torch.Size([150, 1])`, `dtype=torch.float32`\n",
        "\n",
        "Isso está **perfeito** para:\n",
        "\n",
        "* dividir em treino/teste,\n",
        "* jogar num modelo `nn.Linear(4, 1)` (regressão logística),\n",
        "* treinar com `BCEWithLogitsLoss`.\n"
      ],
      "metadata": {
        "id": "u-kg6u4ji-EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definir modelo\n",
        "import torch.nn.functional as F\n",
        "class RedeNeural(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(RedeNeural, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Adicionar print para ver o resultado\n",
        "print(\"Estrutura da Rede Neural:\")\n",
        "print(RedeNeural(input_dim=4, hidden_dim=8, output_dim=1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBJciWV1lkmO",
        "outputId": "9ae436e6-cf9d-4ac5-a464-a39af454bcf5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estrutura da Rede Neural:\n",
            "RedeNeural(\n",
            "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cc974f77"
      },
      "source": [
        "# Task\n",
        "Instanciar o modelo, definir função de perda e otimizador, dividir os dados, treinar o modelo e avaliar o modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eed77c0"
      },
      "source": [
        "## Instanciar o modelo\n",
        "\n",
        "### Subtask:\n",
        "Criar uma instância da classe `RedeNeural` com as dimensões apropriadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "630643e1"
      },
      "source": [
        "**Reasoning**:\n",
        "Instantiate the neural network model with the specified dimensions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1ad4e81",
        "outputId": "1a93b2e8-c4f8-41f5-8d35-52bf075d49dd"
      },
      "source": [
        "modelo = RedeNeural(input_dim=4, hidden_dim=8, output_dim=1)\n",
        "\n",
        "# Adicionar print para ver o resultado\n",
        "print(\"Instância do modelo:\")\n",
        "print(modelo)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instância do modelo:\n",
            "RedeNeural(\n",
            "  (fc1): Linear(in_features=4, out_features=8, bias=True)\n",
            "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e88f7b4"
      },
      "source": [
        "## Definir função de perda e otimizador\n",
        "\n",
        "### Subtask:\n",
        "Escolher uma função de perda adequada para classificação binária e um otimizador (como Adam ou SGD) para atualizar os pesos do modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b131b94f"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary loss function and optimizer, then instantiate them with the model parameters.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9d23e33",
        "outputId": "b86142f8-dfe6-4a81-dd8d-ac8856209730"
      },
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# 3. Definir função de perda e otimizador\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(modelo.parameters(), lr=0.01)\n",
        "\n",
        "# Adicionar prints para confirmar a criação\n",
        "print(\"Função de perda:\")\n",
        "print(criterion)\n",
        "print(\"\\nOtimizador:\")\n",
        "print(optimizer)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Função de perda:\n",
            "BCEWithLogitsLoss()\n",
            "\n",
            "Otimizador:\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    decoupled_weight_decay: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c469391d"
      },
      "source": [
        "## Dividir os dados\n",
        "\n",
        "### Subtask:\n",
        "Separar os dados `X` e `y` em conjuntos de treino e teste para avaliar o desempenho do modelo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9af09a48"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary function for splitting data and then use it to create training and testing sets, printing their shapes to verify the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a619c20",
        "outputId": "525e89fb-0bf7-4b97-857d-b398b3fa3617"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 4. Dividir dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Adicionar prints para verificar as formas\n",
        "print(\"Forma de X_train:\", X_train.shape)\n",
        "print(\"Forma de X_test:\", X_test.shape)\n",
        "print(\"Forma de y_train:\", y_train.shape)\n",
        "print(\"Forma de y_test:\", y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma de X_train: torch.Size([120, 4])\n",
            "Forma de X_test: torch.Size([30, 4])\n",
            "Forma de y_train: torch.Size([120, 1])\n",
            "Forma de y_test: torch.Size([30, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df52a674"
      },
      "source": [
        "## Treinar o modelo\n",
        "\n",
        "### Subtask:\n",
        "Implementar o loop de treinamento, que inclui forward pass, cálculo da perda, backward pass e atualização dos pesos.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b46b0dc3"
      },
      "source": [
        "**Reasoning**:\n",
        "Implement the training loop including forward pass, loss calculation, backward pass, and weight update for a defined number of epochs.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a398d2e9",
        "outputId": "eb909b2b-ebb9-4a14-ca82-78756ab56f9f"
      },
      "source": [
        "# 5. Loop de treinamento\n",
        "epochs = 1000\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    outputs = modelo(X_train)\n",
        "    loss = criterion(outputs, y_train)\n",
        "\n",
        "    # Backward pass e otimização\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # Imprimir a perda a cada 100 épocas\n",
        "    if (epoch + 1) % 100 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [100/1000], Loss: 0.4082\n",
            "Epoch [200/1000], Loss: 0.1322\n",
            "Epoch [300/1000], Loss: 0.0755\n",
            "Epoch [400/1000], Loss: 0.0612\n",
            "Epoch [500/1000], Loss: 0.0553\n",
            "Epoch [600/1000], Loss: 0.0520\n",
            "Epoch [700/1000], Loss: 0.0503\n",
            "Epoch [800/1000], Loss: 0.0492\n",
            "Epoch [900/1000], Loss: 0.0485\n",
            "Epoch [1000/1000], Loss: 0.0479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e31da2d"
      },
      "source": [
        "## Avaliar o modelo\n",
        "\n",
        "### Subtask:\n",
        "Calcular métricas de desempenho (como acurácia) nos dados de teste.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc1c66b6"
      },
      "source": [
        "**Reasoning**:\n",
        "Calculate the accuracy of the trained model on the test set by obtaining predictions, converting them to probabilities and then to predicted classes, and comparing them with the true labels.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bd9ddc4",
        "outputId": "63770955-2b9b-4fa3-efb9-04d83bcb0df5"
      },
      "source": [
        "# 6. Avaliar o modelo\n",
        "modelo.eval()\n",
        "with torch.no_grad():\n",
        "    outputs_test = modelo(X_test)\n",
        "    probabilities = torch.sigmoid(outputs_test)\n",
        "    predicted_classes = (probabilities > 0.5).float()\n",
        "    accuracy = (predicted_classes == y_test).float().mean()\n",
        "\n",
        "print(f'Acurácia nos dados de teste: {accuracy.item():.4f}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia nos dados de teste: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2e0a2394"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   A `RedeNeural` model was successfully instantiated with 4 input features, 8 hidden neurons, and 1 output neuron.\n",
        "*   The `BCEWithLogitsLoss` function was chosen as the loss function, suitable for binary classification, and the `Adam` optimizer with a learning rate of 0.01 was selected to update model weights.\n",
        "*   The dataset was split into training (80%) and testing (20%) sets using `train_test_split`.\n",
        "*   The model was trained for 1000 epochs, showing a decrease in loss from approximately 0.4082 at epoch 100 to 0.0479 at epoch 1000, indicating learning.\n",
        "*   The model achieved an accuracy of 1.0000 on the test dataset, demonstrating perfect classification on this specific test set.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The perfect accuracy on the test set suggests potential overfitting or a very simple dataset. Further validation with a larger, more diverse dataset or cross-validation is recommended to confirm generalization.\n",
        "*   Explore different network architectures, hyperparameters (learning rate, number of epochs, hidden layer size), and regularization techniques to assess their impact on performance and robustness.\n"
      ]
    }
  ]
}