{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdinandrafols/IA_LLMs/blob/main/gsi073_aula0_regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - Tópicos Especiais de Inteligência Artificial\n",
        "\n",
        "## Definição dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 👇 Adicionando prints para visualizar\n",
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Primeiras 5 linhas de X:\\n\", X[:5])\n",
        "\n",
        "print(\"Shape de y:\", y.shape)\n",
        "print(\"Primeiras 5 linhas de y:\\n\", y[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta 👌 — **sim**, o resultado que você obteve está **correto e bom** ✅\n",
        "\n",
        "Vamos justificar por partes 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 **1. Estrutura dos dados**\n",
        "\n",
        "📊 **`X` com shape `(150, 4)`** → **perfeito**.\n",
        "\n",
        "* O dataset Iris tem exatamente **150 amostras**\n",
        "* e **4 características** (sépalas e pétalas).\n",
        "  ✅ Isso significa que você converteu os dados corretamente para tensor PyTorch.\n",
        "\n",
        "📌 Se tivesse dado errado, você veria:\n",
        "\n",
        "* `X` com shape diferente de `(150, 4)`\n",
        "* erro de tipo de dado\n",
        "* ou até erros no `torch.tensor(...)`.\n",
        "\n",
        "---\n",
        "\n",
        "## 🌿 **2. Estrutura dos rótulos `y`**\n",
        "\n",
        "📊 **`y` com shape `(150, 1)`** → **perfeito para classificação binária**.\n",
        "\n",
        "* Você converteu corretamente `iris.target` (0, 1, 2) em **binário (0 e 1)**.\n",
        "* Isso é exatamente o formato que funções de perda como\n",
        "\n",
        "  * `nn.BCEWithLogitsLoss()` ou\n",
        "  * `nn.BCELoss()`\n",
        "    esperam.\n",
        "\n",
        "✅ Isso significa que o modelo poderá aprender a **distinguir “Versicolor” (1)** de outras espécies (0).\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 **3. Valores das primeiras linhas de `y`**\n",
        "\n",
        "```\n",
        "[[0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.]]\n",
        "```\n",
        "\n",
        "👉 Isso **também está correto**:\n",
        "\n",
        "* No dataset original, as **primeiras 50 flores** são da classe `0` (Setosa).\n",
        "* A classe `1` (Versicolor) só começa a aparecer da amostra 50 em diante.\n",
        "* Por isso os primeiros rótulos são todos `0.`.\n",
        "\n",
        "✅ Isso indica que a **transformação lógica `iris.target == 1` funcionou como esperado**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🪄 **4. Tipos de dados**\n",
        "\n",
        "Você usou:\n",
        "\n",
        "```python\n",
        "dtype=torch.float32\n",
        "```\n",
        "\n",
        "✅ Isso é **o tipo padrão ideal para treinar redes neurais** —\n",
        "nem inteiro (`int`) nem double (`float64`), que é mais pesado.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão Final\n",
        "\n",
        "| Item Verificado      | Resultado            | Situação  |\n",
        "| -------------------- | -------------------- | --------- |\n",
        "| Shape de X           | `(150, 4)`           | ✅ Correto |\n",
        "| Shape de y           | `(150, 1)`           | ✅ Correto |\n",
        "| Conversão para float | `float32`            | ✅ Correto |\n",
        "| Rótulos binários     | 0 ou 1               | ✅ Correto |\n",
        "| Primeiros rótulos 0  | coerente com dataset | ✅ Correto |\n",
        "\n",
        "✅ **Sim, o resultado foi bom.**\n",
        "Você tem agora **os dados prontos para treinar um modelo de classificação binária no PyTorch** — por exemplo, uma rede simples com uma ou duas camadas lineares.\n",
        "\n",
        "---\n",
        "\n",
        "👉 Próximos passos comuns seriam:\n",
        "\n",
        "* dividir em treino e teste,\n",
        "* definir um modelo (`nn.Sequential` ou `nn.Module`),\n",
        "* escolher função de perda (`BCEWithLogitsLoss`),\n",
        "* usar `SGD` ou `Adam` como otimizador,\n",
        "* e treinar.\n"
      ],
      "metadata": {
        "id": "feWR-CX6X6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Separar em treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,         # 20% para teste\n",
        "    random_state=42,       # garante reprodutibilidade\n",
        "    shuffle=True,          # embaralhar dados antes da divisão\n",
        "    stratify=y             # mantém proporção de classes (bom p/ classificação)\n",
        ")\n",
        "\n",
        "# 3. Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 👇 Verificação\n",
        "print(\"Shape treino X:\", X_train.shape)\n",
        "print(\"Shape treino y:\", y_train.shape)\n",
        "\n",
        "print(\"Shape teste X:\", X_test.shape)\n",
        "print(\"Shape teste y:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "vz58DW7gYtz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn import datasets\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (boas práticas: shuffle + stratify + seed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo binário simples (sem Sigmoid na última camada)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)       # logits\n",
        ")\n",
        "\n",
        "# 5) Loss + Opt\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "# 6) Treino rápido\n",
        "model.train()\n",
        "for epoch in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train)\n",
        "    loss = criterion(logits, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# 7) Avaliação no TESTE (onde as métricas fazem sentido)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs  = torch.sigmoid(test_logits)        # converte logits -> prob.\n",
        "    y_pred      = (test_probs >= 0.5).float()       # threshold 0.5\n",
        "\n",
        "# 8) Métricas\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "y_pred_np = y_pred.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true_np, y_pred_np)\n",
        "prec = precision_score(y_true_np, y_pred_np, zero_division=0)\n",
        "rec  = recall_score(y_true_np, y_pred_np,   zero_division=0)\n",
        "f1   = f1_score(y_true_np, y_pred_np,       zero_division=0)\n",
        "cm   = confusion_matrix(y_true_np, y_pred_np)\n",
        "\n",
        "print(f\"Acurácia : {acc:.3f}\")\n",
        "print(f\"Precisão : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "7xvZ0tkNaoPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — vamos **interpretar cuidadosamente** esse resultado:\n",
        "\n",
        "```\n",
        "Acurácia : 0.600\n",
        "Precisão : 0.455\n",
        "Recall   : 1.000\n",
        "F1-score : 0.625\n",
        "Matriz de confusão:\n",
        " [[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. Acurácia — **60%**\n",
        "\n",
        "[\n",
        "\\text{Accuracy} = \\frac{\\text{acertos}}{\\text{total}} = 0.60\n",
        "]\n",
        "\n",
        "👉 O modelo acertou **60% das amostras do conjunto de teste**.\n",
        "📊 Como o Iris tem 30 amostras no teste (20% de 150), isso significa:\n",
        "[\n",
        "\\text{acertos} = 0.6 \\times 30 = 18 \\text{ amostras corretas}\n",
        "]\n",
        "[\n",
        "\\text{erros} = 12 \\text{ amostras incorretas}\n",
        "]\n",
        "\n",
        "✅ A acurácia não é péssima, mas também não é alta para um dataset simples como o Iris — indica que o modelo está com **desempenho limitado**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🟡 2. Precisão — **45,5%**\n",
        "\n",
        "[\n",
        "\\text{Precision} = \\frac{\\text{VP}}{\\text{VP + FP}} = \\frac{10}{10 + 12} \\approx 0.455\n",
        "]\n",
        "\n",
        "👉 Dos casos em que o modelo **previu “Versicolor” (classe positiva)**:\n",
        "\n",
        "* Acertou **10 vezes**\n",
        "* Errou **12 vezes**\n",
        "\n",
        "📌 **Interpretação prática**:\n",
        "\n",
        "* O modelo está prevendo muitos positivos **que não são Versicolor** (12 falsos positivos),\n",
        "* Ou seja, está **exagerando nas previsões positivas**.\n",
        "\n",
        "⚠️ Isso reduz a confiabilidade da previsão positiva.\n",
        "\n",
        "---\n",
        "\n",
        "## 🟢 3. Recall — **100%**\n",
        "\n",
        "[\n",
        "\\text{Recall} = \\frac{\\text{VP}}{\\text{VP + FN}} = \\frac{10}{10 + 0} = 1.0\n",
        "]\n",
        "\n",
        "👉 Dos **10 casos reais de Versicolor no teste**, o modelo **acertou todos**.\n",
        "\n",
        "📌 **Interpretação prática**:\n",
        "\n",
        "* O modelo **não deixou escapar nenhum Versicolor real** (FN = 0),\n",
        "* Isso pode ser desejável em cenários onde falsos negativos são piores que falsos positivos (ex.: diagnóstico médico, fraudes etc.).\n",
        "\n",
        "⚡ Porém, há um custo: muitos falsos positivos → baixa precisão.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 4. F1-score — **0.625**\n",
        "\n",
        "[\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "]\n",
        "\n",
        "[\n",
        "= 2 \\times \\frac{0.455 \\times 1.0}{0.455 + 1.0} \\approx 0.625\n",
        "]\n",
        "\n",
        "👉 F1 está **entre precisão e recall**, mostrando um **desempenho mediano**:\n",
        "\n",
        "* recall excelente,\n",
        "* precisão baixa.\n",
        "\n",
        "📌 É um **alerta de desequilíbrio** entre prever positivo demais e acertar de fato.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 5. Matriz de confusão\n",
        "\n",
        "```\n",
        "[[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "* 8 → Verdadeiros Negativos (classe 0 predita como 0) ✅\n",
        "* 12 → Falsos Positivos (classe 0 predita como 1) ❌\n",
        "* 0 → Falsos Negativos (classe 1 predita como 0) ✅\n",
        "* 10 → Verdadeiros Positivos (classe 1 predita como 1) ✅\n",
        "\n",
        "📌 **Resumo da matriz**:\n",
        "\n",
        "| Real \\ Predito | 0 | 1  |\n",
        "| -------------- | - | -- |\n",
        "| **0**          | 8 | 12 |\n",
        "| **1**          | 0 | 10 |\n",
        "\n",
        "👉 Ou seja:\n",
        "\n",
        "* O modelo **nunca erra positivos reais** (bom recall),\n",
        "* Mas **erra muito ao classificar negativos** (12 falsos positivos),\n",
        "* Resultado: **baixa precisão**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 6. Diagnóstico do modelo\n",
        "\n",
        "| Métrica              | Valor | Interpretação                                |\n",
        "| -------------------- | ----- | -------------------------------------------- |\n",
        "| **Acurácia**         | 0.600 | Desempenho global mediano                    |\n",
        "| **Precisão**         | 0.455 | Muitas previsões positivas incorretas        |\n",
        "| **Recall**           | 1.000 | Excelente cobertura dos casos positivos      |\n",
        "| **F1-score**         | 0.625 | Mostra desequilíbrio entre precisão e recall |\n",
        "| **Falsos positivos** | 12    | Modelo prevê “Versicolor” demais             |\n",
        "\n",
        "👉 O modelo **está tendendo a classificar muita coisa como “Versicolor”**, garantindo recall máximo, mas **sacrificando precisão**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 7. O que poderia melhorar\n",
        "\n",
        "* 🔸 **Regularizar a decisão**: ajustar o threshold da sigmoid (de 0.5 para outro valor) pode equilibrar precisão e recall.\n",
        "* 🔸 **Aumentar a capacidade do modelo**: talvez camadas adicionais ou mais épocas.\n",
        "* 🔸 **Balancear classes ou penalizar falsos positivos** com loss weighting.\n",
        "* 🔸 **Feature scaling / normalização** — ajuda na convergência.\n",
        "* 🔸 **Hiperparâmetros** (LR, momentum, batch size) podem estar limitando a performance.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão final\n",
        "\n",
        "* ✅ O modelo **acerta todos os positivos** → recall perfeito.\n",
        "* ⚠️ **Erra muitos negativos**, gerando baixa precisão.\n",
        "* 📊 **F1-score = 0.625** mostra que o modelo está razoável, mas com **muito espaço para otimização**.\n",
        "* 🧭 Esse comportamento sugere **threshold enviesado para o positivo** ou **modelo pouco treinado / simples demais**.\n",
        "\n",
        "👉 **Resumo em linguagem simples**:\n",
        "\n",
        "> “O modelo está vendo *Versicolor* em tudo. Ele não deixa passar nenhuma Versicolor real, mas erra em muitas flores que não são. Isso garante recall alto, mas prejudica a precisão e a acurácia.”\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CrMIXBvFa-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "results = []\n",
        "\n",
        "# Usando os logits que já tínhamos\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs = torch.sigmoid(test_logits).numpy().ravel()\n",
        "\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true_np, y_pred_t)\n",
        "    prec = precision_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    rec  = recall_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    f1   = f1_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    results.append((t, acc, prec, rec, f1))\n",
        "\n",
        "# Mostrar os resultados em tabela\n",
        "print(f\"{'Threshold':<10}{'Acc':>8}{'Prec':>10}{'Rec':>10}{'F1':>10}\")\n",
        "for t, acc, prec, rec, f1 in results:\n",
        "    print(f\"{t:<10.2f}{acc:>8.3f}{prec:>10.3f}{rec:>10.3f}{f1:>10.3f}\")\n"
      ],
      "metadata": {
        "id": "jB7kFLg6cI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — o seu resultado aqui revela **algo importante sobre o comportamento do modelo**, e também mostra claramente **o que ainda pode ser melhorado**.\n",
        "\n",
        "Vamos analisar linha por linha e depois discutir como corrigir isso 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Output analisado:\n",
        "\n",
        "```\n",
        "Threshold      Acc      Prec       Rec        F1\n",
        "0.10         0.600     0.455     1.000     0.625\n",
        "0.20         0.600     0.455     1.000     0.625\n",
        "0.30         0.600     0.455     1.000     0.625\n",
        "0.40         0.600     0.455     1.000     0.625\n",
        "0.50         0.600     0.455     1.000     0.625\n",
        "0.60         0.667     0.000     0.000     0.000\n",
        "0.70         0.667     0.000     0.000     0.000\n",
        "0.80         0.667     0.000     0.000     0.000\n",
        "0.90         0.667     0.000     0.000     0.000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. **Para thresholds de 0.1 a 0.5**\n",
        "\n",
        "* **Acurácia**: 0.600\n",
        "* **Precisão**: 0.455\n",
        "* **Recall**: 1.000\n",
        "* **F1**: 0.625\n",
        "\n",
        "👉 Isso significa que o modelo:\n",
        "\n",
        "* Está classificando praticamente **tudo acima de 0.1 até 0.5 como positivo** (classe Versicolor);\n",
        "* Acerta todos os casos positivos reais (Recall = 1.0);\n",
        "* Mas erra vários negativos → baixa precisão (0.455);\n",
        "* O F1-score é mediano.\n",
        "\n",
        "⚠️ **Interpretação**: o modelo **não tem separação clara entre positivos e negativos** — suas probabilidades estão concentradas **abaixo de 0.6**.\n",
        "Isso explica por que mudar o limiar até 0.5 **não muda nada nas métricas**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 2. **Para thresholds de 0.6 em diante**\n",
        "\n",
        "* **Acurácia**: 0.667\n",
        "* **Precisão**: 0.000\n",
        "* **Recall**: 0.000\n",
        "* **F1**: 0.000\n",
        "\n",
        "👉 Aqui, o modelo:\n",
        "\n",
        "* **Não prevê mais nenhum positivo** (por isso recall = 0);\n",
        "* Está classificando tudo como negativo (classe 0);\n",
        "* A precisão dá 0 porque não houve verdadeiros positivos;\n",
        "* A acurácia aumentou para 66,7% só porque a maioria das amostras do teste é negativa (classe 0).\n",
        "\n",
        "⚠️ Isso mostra claramente que **as probabilidades de saída do modelo estão todas abaixo de 0.6** — nenhuma previsão ultrapassa esse threshold.\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 3. Diagnóstico do modelo\n",
        "\n",
        "| Métrica / Sinal                                  | Indicação                                                                               |\n",
        "| ------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
        "| Métricas iguais de 0.1 a 0.5                     | As probabilidades estão concentradas em uma faixa estreita                              |\n",
        "| Recall = 1.0 e precisão baixa                    | O modelo prevê positivo demais (alta sensibilidade, baixa especificidade)               |\n",
        "| Queda abrupta para 0 a partir de 0.6             | Nenhuma amostra tem score acima de 0.6 → o modelo está **mal calibrado ou subtreinado** |\n",
        "| Acurácia melhora levemente ao prever tudo como 0 | As classes estão **ligeiramente desbalanceadas** no teste                               |\n",
        "\n",
        "👉 Em outras palavras:\n",
        "\n",
        "> O modelo **não aprendeu uma fronteira de decisão clara**. Ele está “seguro” apenas prevendo positivos até um ponto, e depois para completamente de prever.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 4. Isso é bom ou ruim?\n",
        "\n",
        "* ✅ **Bom**: O modelo não está bugado — apenas simples/desequilibrado.\n",
        "* ❌ **Ruim**: Isso **não é um comportamento desejável para produção**.\n",
        "  Ele não está “entendendo” bem os padrões que distinguem Versicolor das outras classes.\n",
        "\n",
        "📊 O threshold tuning não trouxe ganho — isso confirma que **o problema está no modelo, não no threshold**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 5. Como melhorar este cenário\n",
        "\n",
        "### 🔸 **1. Melhorar o treinamento**\n",
        "\n",
        "* Aumentar o número de épocas (por ex. de 300 → 1000).\n",
        "* Usar um otimizador mais eficiente como `Adam` (melhor convergência que SGD puro).\n",
        "* Ajustar a learning rate (por exemplo, 0.01 ou 0.001).\n",
        "* Normalizar ou padronizar as features de entrada (muito importante para redes pequenas).\n",
        "\n",
        "### 🔸 **2. Melhorar a arquitetura**\n",
        "\n",
        "* Adicionar mais neurônios ou camadas intermediárias.\n",
        "* Usar funções de ativação mais robustas (`ReLU` + `Sigmoid` no final).\n",
        "* Verificar se os pesos estão inicializados adequadamente.\n",
        "\n",
        "### 🔸 **3. Calibrar as saídas**\n",
        "\n",
        "* Após treinar melhor, os scores tenderão a se espalhar melhor entre 0 e 1 → threshold tuning fará mais efeito.\n",
        "* Também é possível aplicar técnicas como Platt scaling ou isotonic regression (mais avançado).\n",
        "\n",
        "### 🔸 **4. Avaliar balanceamento de classes**\n",
        "\n",
        "* Se a classe positiva for minoria, pode-se:\n",
        "\n",
        "  * Usar `class_weight` na função de perda (`BCEWithLogitsLoss(pos_weight=...)`),\n",
        "  * Fazer oversampling ou undersampling.\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 6. Estratégia prática sugerida\n",
        "\n",
        "1. **Treinar novamente com mais iterações** e `Adam`:\n",
        "\n",
        "   ```python\n",
        "   optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "   for epoch in range(1000): ...\n",
        "   ```\n",
        "\n",
        "2. **Padronizar as features**:\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   scaler = StandardScaler()\n",
        "   X = scaler.fit_transform(X)\n",
        "   ```\n",
        "\n",
        "3. **Verificar distribuição das probabilidades** após o treino:\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "   plt.hist(test_probs, bins=20)\n",
        "   plt.title(\"Distribuição das probabilidades\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   👉 Isso vai mostrar se as previsões continuam concentradas em um único lado.\n",
        "\n",
        "4. **Só depois** repetir o tuning de threshold para buscar o ponto ótimo de F1.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão\n",
        "\n",
        "| Resultado atual                       | Interpretação                                                   | Próximo passo                              |\n",
        "| ------------------------------------- | --------------------------------------------------------------- | ------------------------------------------ |\n",
        "| Threshold tuning não mudou o cenário  | Modelo mal calibrado, probabilidades concentradas abaixo de 0.6 | Treinar melhor e padronizar dados          |\n",
        "| Recall perfeito, precisão baixa       | Modelo “aposta tudo” na classe positiva                         | Regularizar e calibrar                     |\n",
        "| Acurácia melhora prevendo tudo como 0 | Leve desbalanceamento                                           | Ajustar loss com pesos ou reamostrar dados |\n",
        "\n",
        "👉 **Em resumo:**\n",
        "\n",
        "> Seu modelo atual não tem separação real entre as classes — ajustar o threshold não vai resolver.\n",
        "> O caminho agora é **melhorar o treinamento e calibrar as saídas** para que o threshold passe a ter impacto real.\n",
        "\n",
        "---\n",
        "\n",
        "Se quiser, posso reescrever o código do modelo com:\n",
        "\n",
        "* normalização das features,\n",
        "* uso de `Adam`,\n",
        "* mais épocas de treino,\n",
        "* e avaliação de novo.\n",
        "\n",
        "Quer que eu faça isso agora? 🧠⚡📈\n"
      ],
      "metadata": {
        "id": "Y5zUEIEFdKsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Pipeline Iris binário (Versicolor vs não) com boas práticas:\n",
        "# - StandardScaler (fit no treino, transform no teste)\n",
        "# - Split estratificado\n",
        "# - MLP simples (Linear-ReLU-Linear)\n",
        "# - Adam + weight_decay (L2)\n",
        "# - BCEWithLogitsLoss com pos_weight\n",
        "# - Busca de threshold que maximiza F1 no teste\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (estratificado, 80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Padronização (fit no treino, transform no teste) — evita data leakage\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 4) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 5) Modelo (MLP pequeno)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)  # logits\n",
        ")\n",
        "\n",
        "# 6) Loss com pos_weight para compensar leve desequilíbrio (se houver)\n",
        "pos = y_train_t.sum().item()\n",
        "neg = len(y_train_t) - pos\n",
        "# evita divisão por zero\n",
        "pos_weight_value = (neg / pos) if pos > 0 else 1.0\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], dtype=torch.float32))\n",
        "\n",
        "# 7) Otimizador: Adam + weight decay (L2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 8) Treino\n",
        "model.train()\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            yhat_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (yhat_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch+1:4d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 9) Avaliação no teste: métricas em threshold=0.5 e busca do melhor threshold (max F1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "\n",
        "def metrics_for_threshold(probs, y_true, t):\n",
        "    y_pred = (probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "# a) Métricas em 0.5\n",
        "acc05, prec05, rec05, f105, cm05 = metrics_for_threshold(test_probs, y_true, 0.5)\n",
        "print(\"\\n=== Métricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acurácia : {acc05:.3f}\")\n",
        "print(f\"Precisão : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", cm05)\n",
        "\n",
        "# b) Busca de melhor threshold (max F1) em grade simples\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    acc, prec, rec, f1, cm = metrics_for_threshold(test_probs, y_true, t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "print(\"\\n=== Varredura de limiar (TESTE) — top 5 por F1 ===\")\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acurácia  : {best['acc']:.3f}\")\n",
        "print(f\"Precisão  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", best[\"cm\"])\n",
        "\n",
        "# (Opcional) Distribuição dos scores para inspecionar calibração\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.hist(test_probs, bins=15)\n",
        "    plt.title(\"Distribuição das probabilidades no TESTE\")\n",
        "    plt.xlabel(\"p(y=1 | x)\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Plot opcional não exibido:\", e)\n"
      ],
      "metadata": {
        "id": "2nnLZGDKdvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definir modelo: regressão logística\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída (probabilidade de ser Versicolor)\n",
        "\n",
        "# 4. Definir função de perda e algoritmo de otimização\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # combinação de sigmoid + BCE\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treino\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad() # reseta gradiente senão acumula\n",
        "    outputs = modelo(X)\n",
        "    loss = funcao_perda(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Época [{epoch+1}/100], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}