{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdinandrafols/IA_LLMs/blob/main/gsi073_aula0_regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - T√≥picos Especiais de Intelig√™ncia Artificial\n",
        "\n",
        "## Defini√ß√£o dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: s√©palas e p√©talas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contr√°rio\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# üëá Adicionando prints para visualizar\n",
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Primeiras 5 linhas de X:\\n\", X[:5])\n",
        "\n",
        "print(\"Shape de y:\", y.shape)\n",
        "print(\"Primeiras 5 linhas de y:\\n\", y[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta üëå ‚Äî **sim**, o resultado que voc√™ obteve est√° **correto e bom** ‚úÖ\n",
        "\n",
        "Vamos justificar por partes üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† **1. Estrutura dos dados**\n",
        "\n",
        "üìä **`X` com shape `(150, 4)`** ‚Üí **perfeito**.\n",
        "\n",
        "* O dataset Iris tem exatamente **150 amostras**\n",
        "* e **4 caracter√≠sticas** (s√©palas e p√©talas).\n",
        "  ‚úÖ Isso significa que voc√™ converteu os dados corretamente para tensor PyTorch.\n",
        "\n",
        "üìå Se tivesse dado errado, voc√™ veria:\n",
        "\n",
        "* `X` com shape diferente de `(150, 4)`\n",
        "* erro de tipo de dado\n",
        "* ou at√© erros no `torch.tensor(...)`.\n",
        "\n",
        "---\n",
        "\n",
        "## üåø **2. Estrutura dos r√≥tulos `y`**\n",
        "\n",
        "üìä **`y` com shape `(150, 1)`** ‚Üí **perfeito para classifica√ß√£o bin√°ria**.\n",
        "\n",
        "* Voc√™ converteu corretamente `iris.target` (0, 1, 2) em **bin√°rio (0 e 1)**.\n",
        "* Isso √© exatamente o formato que fun√ß√µes de perda como\n",
        "\n",
        "  * `nn.BCEWithLogitsLoss()` ou\n",
        "  * `nn.BCELoss()`\n",
        "    esperam.\n",
        "\n",
        "‚úÖ Isso significa que o modelo poder√° aprender a **distinguir ‚ÄúVersicolor‚Äù (1)** de outras esp√©cies (0).\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ **3. Valores das primeiras linhas de `y`**\n",
        "\n",
        "```\n",
        "[[0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.]]\n",
        "```\n",
        "\n",
        "üëâ Isso **tamb√©m est√° correto**:\n",
        "\n",
        "* No dataset original, as **primeiras 50 flores** s√£o da classe `0` (Setosa).\n",
        "* A classe `1` (Versicolor) s√≥ come√ßa a aparecer da amostra 50 em diante.\n",
        "* Por isso os primeiros r√≥tulos s√£o todos `0.`.\n",
        "\n",
        "‚úÖ Isso indica que a **transforma√ß√£o l√≥gica `iris.target == 1` funcionou como esperado**.\n",
        "\n",
        "---\n",
        "\n",
        "## ü™Ñ **4. Tipos de dados**\n",
        "\n",
        "Voc√™ usou:\n",
        "\n",
        "```python\n",
        "dtype=torch.float32\n",
        "```\n",
        "\n",
        "‚úÖ Isso √© **o tipo padr√£o ideal para treinar redes neurais** ‚Äî\n",
        "nem inteiro (`int`) nem double (`float64`), que √© mais pesado.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o Final\n",
        "\n",
        "| Item Verificado      | Resultado            | Situa√ß√£o  |\n",
        "| -------------------- | -------------------- | --------- |\n",
        "| Shape de X           | `(150, 4)`           | ‚úÖ Correto |\n",
        "| Shape de y           | `(150, 1)`           | ‚úÖ Correto |\n",
        "| Convers√£o para float | `float32`            | ‚úÖ Correto |\n",
        "| R√≥tulos bin√°rios     | 0 ou 1               | ‚úÖ Correto |\n",
        "| Primeiros r√≥tulos 0  | coerente com dataset | ‚úÖ Correto |\n",
        "\n",
        "‚úÖ **Sim, o resultado foi bom.**\n",
        "Voc√™ tem agora **os dados prontos para treinar um modelo de classifica√ß√£o bin√°ria no PyTorch** ‚Äî por exemplo, uma rede simples com uma ou duas camadas lineares.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Pr√≥ximos passos comuns seriam:\n",
        "\n",
        "* dividir em treino e teste,\n",
        "* definir um modelo (`nn.Sequential` ou `nn.Module`),\n",
        "* escolher fun√ß√£o de perda (`BCEWithLogitsLoss`),\n",
        "* usar `SGD` ou `Adam` como otimizador,\n",
        "* e treinar.\n"
      ],
      "metadata": {
        "id": "feWR-CX6X6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: s√©palas e p√©talas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contr√°rio\n",
        "\n",
        "# 2. Separar em treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,         # 20% para teste\n",
        "    random_state=42,       # garante reprodutibilidade\n",
        "    shuffle=True,          # embaralhar dados antes da divis√£o\n",
        "    stratify=y             # mant√©m propor√ß√£o de classes (bom p/ classifica√ß√£o)\n",
        ")\n",
        "\n",
        "# 3. Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# üëá Verifica√ß√£o\n",
        "print(\"Shape treino X:\", X_train.shape)\n",
        "print(\"Shape treino y:\", y_train.shape)\n",
        "\n",
        "print(\"Shape teste X:\", X_test.shape)\n",
        "print(\"Shape teste y:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "vz58DW7gYtz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn import datasets\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (boas pr√°ticas: shuffle + stratify + seed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo bin√°rio simples (sem Sigmoid na √∫ltima camada)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)       # logits\n",
        ")\n",
        "\n",
        "# 5) Loss + Opt\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "# 6) Treino r√°pido\n",
        "model.train()\n",
        "for epoch in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train)\n",
        "    loss = criterion(logits, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# 7) Avalia√ß√£o no TESTE (onde as m√©tricas fazem sentido)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs  = torch.sigmoid(test_logits)        # converte logits -> prob.\n",
        "    y_pred      = (test_probs >= 0.5).float()       # threshold 0.5\n",
        "\n",
        "# 8) M√©tricas\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "y_pred_np = y_pred.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true_np, y_pred_np)\n",
        "prec = precision_score(y_true_np, y_pred_np, zero_division=0)\n",
        "rec  = recall_score(y_true_np, y_pred_np,   zero_division=0)\n",
        "f1   = f1_score(y_true_np, y_pred_np,       zero_division=0)\n",
        "cm   = confusion_matrix(y_true_np, y_pred_np)\n",
        "\n",
        "print(f\"Acur√°cia : {acc:.3f}\")\n",
        "print(f\"Precis√£o : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "7xvZ0tkNaoPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî vamos **interpretar cuidadosamente** esse resultado:\n",
        "\n",
        "```\n",
        "Acur√°cia : 0.600\n",
        "Precis√£o : 0.455\n",
        "Recall   : 1.000\n",
        "F1-score : 0.625\n",
        "Matriz de confus√£o:\n",
        " [[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. Acur√°cia ‚Äî **60%**\n",
        "\n",
        "[\n",
        "\\text{Accuracy} = \\frac{\\text{acertos}}{\\text{total}} = 0.60\n",
        "]\n",
        "\n",
        "üëâ O modelo acertou **60% das amostras do conjunto de teste**.\n",
        "üìä Como o Iris tem 30 amostras no teste (20% de 150), isso significa:\n",
        "[\n",
        "\\text{acertos} = 0.6 \\times 30 = 18 \\text{ amostras corretas}\n",
        "]\n",
        "[\n",
        "\\text{erros} = 12 \\text{ amostras incorretas}\n",
        "]\n",
        "\n",
        "‚úÖ A acur√°cia n√£o √© p√©ssima, mas tamb√©m n√£o √© alta para um dataset simples como o Iris ‚Äî indica que o modelo est√° com **desempenho limitado**.\n",
        "\n",
        "---\n",
        "\n",
        "## üü° 2. Precis√£o ‚Äî **45,5%**\n",
        "\n",
        "[\n",
        "\\text{Precision} = \\frac{\\text{VP}}{\\text{VP + FP}} = \\frac{10}{10 + 12} \\approx 0.455\n",
        "]\n",
        "\n",
        "üëâ Dos casos em que o modelo **previu ‚ÄúVersicolor‚Äù (classe positiva)**:\n",
        "\n",
        "* Acertou **10 vezes**\n",
        "* Errou **12 vezes**\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica**:\n",
        "\n",
        "* O modelo est√° prevendo muitos positivos **que n√£o s√£o Versicolor** (12 falsos positivos),\n",
        "* Ou seja, est√° **exagerando nas previs√µes positivas**.\n",
        "\n",
        "‚ö†Ô∏è Isso reduz a confiabilidade da previs√£o positiva.\n",
        "\n",
        "---\n",
        "\n",
        "## üü¢ 3. Recall ‚Äî **100%**\n",
        "\n",
        "[\n",
        "\\text{Recall} = \\frac{\\text{VP}}{\\text{VP + FN}} = \\frac{10}{10 + 0} = 1.0\n",
        "]\n",
        "\n",
        "üëâ Dos **10 casos reais de Versicolor no teste**, o modelo **acertou todos**.\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica**:\n",
        "\n",
        "* O modelo **n√£o deixou escapar nenhum Versicolor real** (FN = 0),\n",
        "* Isso pode ser desej√°vel em cen√°rios onde falsos negativos s√£o piores que falsos positivos (ex.: diagn√≥stico m√©dico, fraudes etc.).\n",
        "\n",
        "‚ö° Por√©m, h√° um custo: muitos falsos positivos ‚Üí baixa precis√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ 4. F1-score ‚Äî **0.625**\n",
        "\n",
        "[\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "]\n",
        "\n",
        "[\n",
        "= 2 \\times \\frac{0.455 \\times 1.0}{0.455 + 1.0} \\approx 0.625\n",
        "]\n",
        "\n",
        "üëâ F1 est√° **entre precis√£o e recall**, mostrando um **desempenho mediano**:\n",
        "\n",
        "* recall excelente,\n",
        "* precis√£o baixa.\n",
        "\n",
        "üìå √â um **alerta de desequil√≠brio** entre prever positivo demais e acertar de fato.\n",
        "\n",
        "---\n",
        "\n",
        "## üßæ 5. Matriz de confus√£o\n",
        "\n",
        "```\n",
        "[[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "* 8 ‚Üí Verdadeiros Negativos (classe 0 predita como 0) ‚úÖ\n",
        "* 12 ‚Üí Falsos Positivos (classe 0 predita como 1) ‚ùå\n",
        "* 0 ‚Üí Falsos Negativos (classe 1 predita como 0) ‚úÖ\n",
        "* 10 ‚Üí Verdadeiros Positivos (classe 1 predita como 1) ‚úÖ\n",
        "\n",
        "üìå **Resumo da matriz**:\n",
        "\n",
        "| Real \\ Predito | 0 | 1  |\n",
        "| -------------- | - | -- |\n",
        "| **0**          | 8 | 12 |\n",
        "| **1**          | 0 | 10 |\n",
        "\n",
        "üëâ Ou seja:\n",
        "\n",
        "* O modelo **nunca erra positivos reais** (bom recall),\n",
        "* Mas **erra muito ao classificar negativos** (12 falsos positivos),\n",
        "* Resultado: **baixa precis√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 6. Diagn√≥stico do modelo\n",
        "\n",
        "| M√©trica              | Valor | Interpreta√ß√£o                                |\n",
        "| -------------------- | ----- | -------------------------------------------- |\n",
        "| **Acur√°cia**         | 0.600 | Desempenho global mediano                    |\n",
        "| **Precis√£o**         | 0.455 | Muitas previs√µes positivas incorretas        |\n",
        "| **Recall**           | 1.000 | Excelente cobertura dos casos positivos      |\n",
        "| **F1-score**         | 0.625 | Mostra desequil√≠brio entre precis√£o e recall |\n",
        "| **Falsos positivos** | 12    | Modelo prev√™ ‚ÄúVersicolor‚Äù demais             |\n",
        "\n",
        "üëâ O modelo **est√° tendendo a classificar muita coisa como ‚ÄúVersicolor‚Äù**, garantindo recall m√°ximo, mas **sacrificando precis√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 7. O que poderia melhorar\n",
        "\n",
        "* üî∏ **Regularizar a decis√£o**: ajustar o threshold da sigmoid (de 0.5 para outro valor) pode equilibrar precis√£o e recall.\n",
        "* üî∏ **Aumentar a capacidade do modelo**: talvez camadas adicionais ou mais √©pocas.\n",
        "* üî∏ **Balancear classes ou penalizar falsos positivos** com loss weighting.\n",
        "* üî∏ **Feature scaling / normaliza√ß√£o** ‚Äî ajuda na converg√™ncia.\n",
        "* üî∏ **Hiperpar√¢metros** (LR, momentum, batch size) podem estar limitando a performance.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o final\n",
        "\n",
        "* ‚úÖ O modelo **acerta todos os positivos** ‚Üí recall perfeito.\n",
        "* ‚ö†Ô∏è **Erra muitos negativos**, gerando baixa precis√£o.\n",
        "* üìä **F1-score = 0.625** mostra que o modelo est√° razo√°vel, mas com **muito espa√ßo para otimiza√ß√£o**.\n",
        "* üß≠ Esse comportamento sugere **threshold enviesado para o positivo** ou **modelo pouco treinado / simples demais**.\n",
        "\n",
        "üëâ **Resumo em linguagem simples**:\n",
        "\n",
        "> ‚ÄúO modelo est√° vendo *Versicolor* em tudo. Ele n√£o deixa passar nenhuma Versicolor real, mas erra em muitas flores que n√£o s√£o. Isso garante recall alto, mas prejudica a precis√£o e a acur√°cia.‚Äù\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CrMIXBvFa-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "results = []\n",
        "\n",
        "# Usando os logits que j√° t√≠nhamos\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs = torch.sigmoid(test_logits).numpy().ravel()\n",
        "\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true_np, y_pred_t)\n",
        "    prec = precision_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    rec  = recall_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    f1   = f1_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    results.append((t, acc, prec, rec, f1))\n",
        "\n",
        "# Mostrar os resultados em tabela\n",
        "print(f\"{'Threshold':<10}{'Acc':>8}{'Prec':>10}{'Rec':>10}{'F1':>10}\")\n",
        "for t, acc, prec, rec, f1 in results:\n",
        "    print(f\"{t:<10.2f}{acc:>8.3f}{prec:>10.3f}{rec:>10.3f}{f1:>10.3f}\")\n"
      ],
      "metadata": {
        "id": "jB7kFLg6cI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî o seu resultado aqui revela **algo importante sobre o comportamento do modelo**, e tamb√©m mostra claramente **o que ainda pode ser melhorado**.\n",
        "\n",
        "Vamos analisar linha por linha e depois discutir como corrigir isso üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Output analisado:\n",
        "\n",
        "```\n",
        "Threshold      Acc      Prec       Rec        F1\n",
        "0.10         0.600     0.455     1.000     0.625\n",
        "0.20         0.600     0.455     1.000     0.625\n",
        "0.30         0.600     0.455     1.000     0.625\n",
        "0.40         0.600     0.455     1.000     0.625\n",
        "0.50         0.600     0.455     1.000     0.625\n",
        "0.60         0.667     0.000     0.000     0.000\n",
        "0.70         0.667     0.000     0.000     0.000\n",
        "0.80         0.667     0.000     0.000     0.000\n",
        "0.90         0.667     0.000     0.000     0.000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. **Para thresholds de 0.1 a 0.5**\n",
        "\n",
        "* **Acur√°cia**: 0.600\n",
        "* **Precis√£o**: 0.455\n",
        "* **Recall**: 1.000\n",
        "* **F1**: 0.625\n",
        "\n",
        "üëâ Isso significa que o modelo:\n",
        "\n",
        "* Est√° classificando praticamente **tudo acima de 0.1 at√© 0.5 como positivo** (classe Versicolor);\n",
        "* Acerta todos os casos positivos reais (Recall = 1.0);\n",
        "* Mas erra v√°rios negativos ‚Üí baixa precis√£o (0.455);\n",
        "* O F1-score √© mediano.\n",
        "\n",
        "‚ö†Ô∏è **Interpreta√ß√£o**: o modelo **n√£o tem separa√ß√£o clara entre positivos e negativos** ‚Äî suas probabilidades est√£o concentradas **abaixo de 0.6**.\n",
        "Isso explica por que mudar o limiar at√© 0.5 **n√£o muda nada nas m√©tricas**.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ 2. **Para thresholds de 0.6 em diante**\n",
        "\n",
        "* **Acur√°cia**: 0.667\n",
        "* **Precis√£o**: 0.000\n",
        "* **Recall**: 0.000\n",
        "* **F1**: 0.000\n",
        "\n",
        "üëâ Aqui, o modelo:\n",
        "\n",
        "* **N√£o prev√™ mais nenhum positivo** (por isso recall = 0);\n",
        "* Est√° classificando tudo como negativo (classe 0);\n",
        "* A precis√£o d√° 0 porque n√£o houve verdadeiros positivos;\n",
        "* A acur√°cia aumentou para 66,7% s√≥ porque a maioria das amostras do teste √© negativa (classe 0).\n",
        "\n",
        "‚ö†Ô∏è Isso mostra claramente que **as probabilidades de sa√≠da do modelo est√£o todas abaixo de 0.6** ‚Äî nenhuma previs√£o ultrapassa esse threshold.\n",
        "\n",
        "---\n",
        "\n",
        "## üìå 3. Diagn√≥stico do modelo\n",
        "\n",
        "| M√©trica / Sinal                                  | Indica√ß√£o                                                                               |\n",
        "| ------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
        "| M√©tricas iguais de 0.1 a 0.5                     | As probabilidades est√£o concentradas em uma faixa estreita                              |\n",
        "| Recall = 1.0 e precis√£o baixa                    | O modelo prev√™ positivo demais (alta sensibilidade, baixa especificidade)               |\n",
        "| Queda abrupta para 0 a partir de 0.6             | Nenhuma amostra tem score acima de 0.6 ‚Üí o modelo est√° **mal calibrado ou subtreinado** |\n",
        "| Acur√°cia melhora levemente ao prever tudo como 0 | As classes est√£o **ligeiramente desbalanceadas** no teste                               |\n",
        "\n",
        "üëâ Em outras palavras:\n",
        "\n",
        "> O modelo **n√£o aprendeu uma fronteira de decis√£o clara**. Ele est√° ‚Äúseguro‚Äù apenas prevendo positivos at√© um ponto, e depois para completamente de prever.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 4. Isso √© bom ou ruim?\n",
        "\n",
        "* ‚úÖ **Bom**: O modelo n√£o est√° bugado ‚Äî apenas simples/desequilibrado.\n",
        "* ‚ùå **Ruim**: Isso **n√£o √© um comportamento desej√°vel para produ√ß√£o**.\n",
        "  Ele n√£o est√° ‚Äúentendendo‚Äù bem os padr√µes que distinguem Versicolor das outras classes.\n",
        "\n",
        "üìä O threshold tuning n√£o trouxe ganho ‚Äî isso confirma que **o problema est√° no modelo, n√£o no threshold**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 5. Como melhorar este cen√°rio\n",
        "\n",
        "### üî∏ **1. Melhorar o treinamento**\n",
        "\n",
        "* Aumentar o n√∫mero de √©pocas (por ex. de 300 ‚Üí 1000).\n",
        "* Usar um otimizador mais eficiente como `Adam` (melhor converg√™ncia que SGD puro).\n",
        "* Ajustar a learning rate (por exemplo, 0.01 ou 0.001).\n",
        "* Normalizar ou padronizar as features de entrada (muito importante para redes pequenas).\n",
        "\n",
        "### üî∏ **2. Melhorar a arquitetura**\n",
        "\n",
        "* Adicionar mais neur√¥nios ou camadas intermedi√°rias.\n",
        "* Usar fun√ß√µes de ativa√ß√£o mais robustas (`ReLU` + `Sigmoid` no final).\n",
        "* Verificar se os pesos est√£o inicializados adequadamente.\n",
        "\n",
        "### üî∏ **3. Calibrar as sa√≠das**\n",
        "\n",
        "* Ap√≥s treinar melhor, os scores tender√£o a se espalhar melhor entre 0 e 1 ‚Üí threshold tuning far√° mais efeito.\n",
        "* Tamb√©m √© poss√≠vel aplicar t√©cnicas como Platt scaling ou isotonic regression (mais avan√ßado).\n",
        "\n",
        "### üî∏ **4. Avaliar balanceamento de classes**\n",
        "\n",
        "* Se a classe positiva for minoria, pode-se:\n",
        "\n",
        "  * Usar `class_weight` na fun√ß√£o de perda (`BCEWithLogitsLoss(pos_weight=...)`),\n",
        "  * Fazer oversampling ou undersampling.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà 6. Estrat√©gia pr√°tica sugerida\n",
        "\n",
        "1. **Treinar novamente com mais itera√ß√µes** e `Adam`:\n",
        "\n",
        "   ```python\n",
        "   optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "   for epoch in range(1000): ...\n",
        "   ```\n",
        "\n",
        "2. **Padronizar as features**:\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   scaler = StandardScaler()\n",
        "   X = scaler.fit_transform(X)\n",
        "   ```\n",
        "\n",
        "3. **Verificar distribui√ß√£o das probabilidades** ap√≥s o treino:\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "   plt.hist(test_probs, bins=20)\n",
        "   plt.title(\"Distribui√ß√£o das probabilidades\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   üëâ Isso vai mostrar se as previs√µes continuam concentradas em um √∫nico lado.\n",
        "\n",
        "4. **S√≥ depois** repetir o tuning de threshold para buscar o ponto √≥timo de F1.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o\n",
        "\n",
        "| Resultado atual                       | Interpreta√ß√£o                                                   | Pr√≥ximo passo                              |\n",
        "| ------------------------------------- | --------------------------------------------------------------- | ------------------------------------------ |\n",
        "| Threshold tuning n√£o mudou o cen√°rio  | Modelo mal calibrado, probabilidades concentradas abaixo de 0.6 | Treinar melhor e padronizar dados          |\n",
        "| Recall perfeito, precis√£o baixa       | Modelo ‚Äúaposta tudo‚Äù na classe positiva                         | Regularizar e calibrar                     |\n",
        "| Acur√°cia melhora prevendo tudo como 0 | Leve desbalanceamento                                           | Ajustar loss com pesos ou reamostrar dados |\n",
        "\n",
        "üëâ **Em resumo:**\n",
        "\n",
        "> Seu modelo atual n√£o tem separa√ß√£o real entre as classes ‚Äî ajustar o threshold n√£o vai resolver.\n",
        "> O caminho agora √© **melhorar o treinamento e calibrar as sa√≠das** para que o threshold passe a ter impacto real.\n",
        "\n",
        "---\n",
        "\n",
        "Se quiser, posso reescrever o c√≥digo do modelo com:\n",
        "\n",
        "* normaliza√ß√£o das features,\n",
        "* uso de `Adam`,\n",
        "* mais √©pocas de treino,\n",
        "* e avalia√ß√£o de novo.\n",
        "\n",
        "Quer que eu fa√ßa isso agora? üß†‚ö°üìà\n"
      ],
      "metadata": {
        "id": "Y5zUEIEFdKsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Pipeline Iris bin√°rio (Versicolor vs n√£o) com boas pr√°ticas:\n",
        "# - StandardScaler (fit no treino, transform no teste)\n",
        "# - Split estratificado\n",
        "# - MLP simples (Linear-ReLU-Linear)\n",
        "# - Adam + weight_decay (L2)\n",
        "# - BCEWithLogitsLoss com pos_weight\n",
        "# - Busca de threshold que maximiza F1 no teste\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (estratificado, 80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Padroniza√ß√£o (fit no treino, transform no teste) ‚Äî evita data leakage\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 4) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 5) Modelo (MLP pequeno)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)  # logits\n",
        ")\n",
        "\n",
        "# 6) Loss com pos_weight para compensar leve desequil√≠brio (se houver)\n",
        "pos = y_train_t.sum().item()\n",
        "neg = len(y_train_t) - pos\n",
        "# evita divis√£o por zero\n",
        "pos_weight_value = (neg / pos) if pos > 0 else 1.0\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], dtype=torch.float32))\n",
        "\n",
        "# 7) Otimizador: Adam + weight decay (L2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 8) Treino\n",
        "model.train()\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            yhat_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (yhat_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch+1:4d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 9) Avalia√ß√£o no teste: m√©tricas em threshold=0.5 e busca do melhor threshold (max F1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "\n",
        "def metrics_for_threshold(probs, y_true, t):\n",
        "    y_pred = (probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "# a) M√©tricas em 0.5\n",
        "acc05, prec05, rec05, f105, cm05 = metrics_for_threshold(test_probs, y_true, 0.5)\n",
        "print(\"\\n=== M√©tricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acur√°cia : {acc05:.3f}\")\n",
        "print(f\"Precis√£o : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", cm05)\n",
        "\n",
        "# b) Busca de melhor threshold (max F1) em grade simples\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    acc, prec, rec, f1, cm = metrics_for_threshold(test_probs, y_true, t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "print(\"\\n=== Varredura de limiar (TESTE) ‚Äî top 5 por F1 ===\")\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acur√°cia  : {best['acc']:.3f}\")\n",
        "print(f\"Precis√£o  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", best[\"cm\"])\n",
        "\n",
        "# (Opcional) Distribui√ß√£o dos scores para inspecionar calibra√ß√£o\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.hist(test_probs, bins=15)\n",
        "    plt.title(\"Distribui√ß√£o das probabilidades no TESTE\")\n",
        "    plt.xlabel(\"p(y=1 | x)\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Plot opcional n√£o exibido:\", e)\n"
      ],
      "metadata": {
        "id": "2nnLZGDKdvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta üëå ‚Äî com base nesse output, **sim**, voc√™ tem um **modelo preditivo muito bom** para este problema. Vamos analisar tecnicamente cada ponto üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üìà 1. **Treinamento est√°vel e preciso**\n",
        "\n",
        "```\n",
        "[ 200/1000] loss=0.0621  acc_train@0.5=0.983\n",
        "[ 400/1000] loss=0.0478  acc_train@0.5=0.983\n",
        "[ 600/1000] loss=0.0396  acc_train@0.5=0.992\n",
        "[ 800/1000] loss=0.0362  acc_train@0.5=0.992\n",
        "[1000/1000] loss=0.0347  acc_train@0.5=0.992\n",
        "```\n",
        "\n",
        "‚úÖ **An√°lise:**\n",
        "\n",
        "* A **loss caiu de 0.0621 ‚Üí 0.0347**, sinal de que o modelo est√° **aprendendo e convergindo bem**.\n",
        "* A **acur√°cia no treino passou de 98,3% para 99,2%** ‚Äî quase perfeita.\n",
        "* N√£o h√° oscila√ß√£o brusca ‚Üí indica estabilidade no processo de otimiza√ß√£o com Adam.\n",
        "\n",
        "üìå Isso j√° sugere um bom modelo, mas **o mais importante** √© verificar o desempenho **no conjunto de teste**, que vem a seguir.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 2. **Desempenho no conjunto de teste (threshold = 0.5)**\n",
        "\n",
        "```\n",
        "Acur√°cia : 0.967\n",
        "Precis√£o : 1.000\n",
        "Recall   : 0.900\n",
        "F1-score : 0.947\n",
        "Matriz de confus√£o:\n",
        " [[20  0]\n",
        " [ 1  9]]\n",
        "```\n",
        "\n",
        "‚úÖ **Interpreta√ß√£o:**\n",
        "\n",
        "* **Acur√°cia de 96,7%** ‚Üí o modelo acerta quase todas as previs√µes no teste.\n",
        "* **Precis√£o de 100%** ‚Üí quando ele prev√™ que √© *Versicolor*, ele **nunca erra**.\n",
        "  ‚Üí Nenhum **falso positivo**.\n",
        "* **Recall de 90%** ‚Üí ele identificou 9 de 10 Versicolor reais, ou seja, **s√≥ deixou passar 1 caso positivo**.\n",
        "* **F1-score de 0.947** ‚Üí equil√≠brio excelente entre precis√£o e recall.\n",
        "\n",
        "üìä Matriz de confus√£o:\n",
        "\n",
        "| Real \\ Predito | 0  | 1 |\n",
        "| -------------- | -- | - |\n",
        "| **0** (neg)    | 20 | 0 |\n",
        "| **1** (pos)    | 1  | 9 |\n",
        "\n",
        "üëâ O modelo:\n",
        "\n",
        "* Acertou todos os 20 negativos (classe 0)\n",
        "* Acertou 9 de 10 positivos (classe 1)\n",
        "* N√£o cometeu falsos positivos (muito bom para classificadores bin√°rios)\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 3. **Tuning de limiar (threshold)**\n",
        "\n",
        "```\n",
        "Top 5 thresholds\n",
        "Thr   Acc   Prec    Rec     F1\n",
        "0.35  0.967  1.000  0.900  0.947\n",
        "0.40  0.967  1.000  0.900  0.947\n",
        "0.45  0.967  1.000  0.900  0.947\n",
        "0.50  0.967  1.000  0.900  0.947\n",
        "0.55  0.967  1.000  0.900  0.947\n",
        "```\n",
        "\n",
        "‚úÖ **Interpreta√ß√£o:**\n",
        "\n",
        "* O desempenho n√£o muda muito com o limiar de 0.35 a 0.55 ‚Üí indica que o **modelo est√° bem calibrado**.\n",
        "* Isso sugere que as probabilidades previstas t√™m **boa separa√ß√£o entre classes**.\n",
        "* Como a precis√£o j√° √© perfeita e o recall alto, **n√£o h√° ganho real ao ajustar o threshold**.\n",
        "\n",
        "üìå Isso √© sinal de **modelo maduro e est√°vel**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 4. Diagn√≥stico geral\n",
        "\n",
        "| M√©trica               | Valor         | Interpreta√ß√£o                                  |\n",
        "| --------------------- | ------------- | ---------------------------------------------- |\n",
        "| Loss final baixa      | 0.0347        | Modelo aprendeu bem a rela√ß√£o input-output     |\n",
        "| Acur√°cia treino/teste | 0.992 / 0.967 | Pouca diferen√ßa ‚Äî n√£o h√° overfitting relevante |\n",
        "| Precis√£o no teste     | 1.000         | Nenhum falso positivo                          |\n",
        "| Recall no teste       | 0.900         | Pouqu√≠ssimos falsos negativos                  |\n",
        "| F1-score              | 0.947         | Excelente equil√≠brio                           |\n",
        "| Threshold tuning      | Est√°vel       | Modelo bem calibrado, previs√µes consistentes   |\n",
        "\n",
        "‚úÖ Isso indica um **modelo robusto**, com **generaliza√ß√£o muito boa**, e **alto poder preditivo**.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° 5. Poss√≠veis (pequenos) ajustes se quisesse ir al√©m\n",
        "\n",
        "Mesmo com desempenho excelente, voc√™ poderia:\n",
        "\n",
        "* üìä **Aumentar recall de 0.90 ‚Üí 1.00**\n",
        "  ‚Üí Ajustando levemente o threshold para baixo (ex.: 0.30‚Äì0.35) ou fazendo leve oversampling da classe positiva durante o treino.\n",
        "\n",
        "* üß™ **Fazer valida√ß√£o cruzada (K-Fold)** para garantir que esses resultados n√£o s√£o fruto do acaso no split.\n",
        "\n",
        "* üß† **Testar dropout leve** para garantir ainda mais robustez contra overfitting.\n",
        "\n",
        "* üìà **Avaliar curva ROC e AUC** para confirmar separa√ß√£o √≥tima de classes.\n",
        "\n",
        "---\n",
        "\n",
        "## üèÅ Conclus√£o\n",
        "\n",
        "üëâ **Sim, voc√™ tem um excelente modelo preditivo.**\n",
        "\n",
        "* Ele generaliza bem (sem overfitting),\n",
        "* Tem precis√£o perfeita, recall alto e F1 robusto,\n",
        "* E responde de forma est√°vel a mudan√ßas de threshold.\n",
        "\n",
        "‚úÖ **Indicadores de modelo preditivo forte:**\n",
        "\n",
        "* Baixa loss final\n",
        "* Alta acur√°cia no teste\n",
        "* Alta precis√£o e recall\n",
        "* F1 pr√≥ximo de 1\n",
        "* Threshold tuning est√°vel\n",
        "\n",
        "üöÄ **Resumo em linguagem simples:**\n",
        "\n",
        "> ‚ÄúSeu modelo aprendeu muito bem a diferenciar Versicolor das outras flores. Ele praticamente n√£o erra, est√° bem calibrado e responde de forma consistente. Para aplica√ß√µes reais, j√° est√° em um patamar excelente.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "Se voc√™ quiser, posso **plotar a curva ROC e calcular AUC** para dar uma **vis√£o estat√≠stica adicional** da separa√ß√£o entre classes. Quer que eu fa√ßa isso? üìàüß†‚ú®\n"
      ],
      "metadata": {
        "id": "vz71o9UiezwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defini√ß√£o do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 3. Definir modelo: regress√£o log√≠stica\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features ‚Üí 1 sa√≠da (probabilidade de ser Versicolor)\n",
        "\n",
        "# 4. Definir fun√ß√£o de perda e algoritmo de otimiza√ß√£o\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # Sigmoid + Binary Cross Entropy\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)\n",
        "\n",
        "# üëá Adicionando prints\n",
        "print(\"Modelo definido:\\n\", modelo)\n",
        "print(\"\\nPar√¢metros iniciais do modelo:\")\n",
        "for nome, param in modelo.named_parameters():\n",
        "    print(f\"{nome}: {param.data}\")\n",
        "\n",
        "print(\"\\nFun√ß√£o de perda:\", funcao_perda)\n",
        "print(\"\\nOtimizador:\", optimizer)\n"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî esse √© o **estado inicial do seu modelo de regress√£o log√≠stica bin√°ria** em PyTorch.\n",
        "Vamos destrinchar cada parte dos resultados para entender **o que eles significam na pr√°tica** antes de iniciar o treinamento üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. **Arquitetura do modelo**\n",
        "\n",
        "```\n",
        "Modelo definido:\n",
        " Linear(in_features=4, out_features=1, bias=True)\n",
        "```\n",
        "\n",
        "üëâ Isso significa que:\n",
        "\n",
        "* O modelo √© uma **camada linear** com:\n",
        "\n",
        "  * `4` entradas (features: comprimento e largura de s√©pala e p√©tala no dataset Iris),\n",
        "  * `1` sa√≠da (logit ‚Äî usado depois pela Sigmoid para gerar probabilidade de ‚ÄúVersicolor‚Äù).\n",
        "* `bias=True` ‚Üí o modelo tem um termo de intercepto (b) al√©m dos pesos.\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica:**\n",
        "Este modelo √© exatamente equivalente a **uma regress√£o log√≠stica cl√°ssica**:\n",
        "[\n",
        "\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + b)\n",
        "]\n",
        "onde (\\sigma) √© a fun√ß√£o sigmoide.\n",
        "\n",
        "---\n",
        "\n",
        "## ü™ú 2. **Par√¢metros iniciais**\n",
        "\n",
        "```\n",
        "weight: tensor([[-0.0660, -0.3629,  0.0117, -0.3415]])\n",
        "bias: tensor([-0.4242])\n",
        "```\n",
        "\n",
        "üëâ Estes s√£o os **valores iniciais dos pesos e bias**, atribu√≠dos aleatoriamente por PyTorch.\n",
        "\n",
        "* `weight` ‚Üí vetor de 4 valores, um para cada feature:\n",
        "\n",
        "  * x‚ÇÅ: -0.0660\n",
        "  * x‚ÇÇ: -0.3629\n",
        "  * x‚ÇÉ:  0.0117\n",
        "  * x‚ÇÑ: -0.3415\n",
        "\n",
        "* `bias` ‚Üí -0.4242\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica:**\n",
        "\n",
        "* No in√≠cio, o modelo **n√£o aprendeu nada ainda**.\n",
        "* Esses valores n√£o t√™m nenhum significado estat√≠stico real.\n",
        "* Ap√≥s algumas itera√ß√µes de gradiente descendente, esses n√∫meros v√£o **se ajustar** para refletir os padr√µes do dataset Iris.\n",
        "\n",
        "‚ö†Ô∏è Importante:\n",
        "Mesmo valores pequenos **podem gerar probabilidades enviesadas no in√≠cio**, especialmente com bias negativo ‚Äî mas isso √© normal.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ 3. **Fun√ß√£o de perda**\n",
        "\n",
        "```\n",
        "Fun√ß√£o de perda: BCEWithLogitsLoss()\n",
        "```\n",
        "\n",
        "üëâ Essa loss combina duas coisas:\n",
        "\n",
        "1. A transforma√ß√£o **Sigmoid** dos logits ‚Üí converte a sa√≠da linear (ex. 0.87) para probabilidade (ex. 0.70),\n",
        "2. O c√°lculo da **Binary Cross Entropy**, que mede qu√£o distante essa probabilidade est√° do r√≥tulo real (0 ou 1).\n",
        "\n",
        "[\n",
        "\\text{Loss} = -[y \\cdot \\log(\\sigma(z)) + (1 - y) \\cdot \\log(1 - \\sigma(z))]\n",
        "]\n",
        "\n",
        "‚úÖ Vantagem: usar `BCEWithLogitsLoss` √© **mais numericamente est√°vel** que usar `Sigmoid` + `BCELoss` separadamente.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö° 4. **Otimizador**\n",
        "\n",
        "```\n",
        "Otimizador: SGD (\n",
        "    lr: 0.1\n",
        "    momentum: 0\n",
        "    weight_decay: 0\n",
        ")\n",
        "```\n",
        "\n",
        "üëâ Esse √© o **otimizador de gradiente descendente estoc√°stico** (Stochastic Gradient Descent):\n",
        "\n",
        "* **`lr=0.1`** ‚Üí taxa de aprendizado relativamente alta (o modelo vai atualizar par√¢metros com passos largos).\n",
        "* **`momentum=0`** ‚Üí sem suaviza√ß√£o extra no caminho de descida (treino mais ‚Äúdireto‚Äù).\n",
        "* **`weight_decay=0`** ‚Üí sem regulariza√ß√£o L2 no momento.\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica:**\n",
        "\n",
        "* Isso √© suficiente para modelos pequenos como regress√£o log√≠stica.\n",
        "* Mas se o treino oscilar muito ou n√£o convergir, **ajustar `lr` ou adicionar momentum** ajuda.\n",
        "* Em problemas maiores, usar Adam costuma ser mais eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 5. **Diagn√≥stico do estado inicial**\n",
        "\n",
        "| Elemento                | Valor atual                   | Interpreta√ß√£o                               |\n",
        "| ----------------------- | ----------------------------- | ------------------------------------------- |\n",
        "| Arquitetura             | Linear(4‚Üí1)                   | Modelo de regress√£o log√≠stica bin√°ria       |\n",
        "| Pesos e bias            | valores pequenos e aleat√≥rios | Ponto de partida neutro para aprendizado    |\n",
        "| Fun√ß√£o de perda         | BCEWithLogitsLoss             | Ideal para classifica√ß√£o bin√°ria            |\n",
        "| Otimizador              | SGD, lr=0.1                   | Simples, eficiente p/ modelo pequeno        |\n",
        "| Momento / regulariza√ß√£o | momentum=0, weight_decay=0    | Treino ‚Äúcru‚Äù ‚Äî suficiente para caso simples |\n",
        "\n",
        "‚úÖ Isso est√° **exatamente como deveria estar antes de iniciar o treinamento**.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Em resumo:\n",
        "\n",
        "* O modelo ainda **n√£o tem nenhum conhecimento** ‚Äî est√° pronto para aprender.\n",
        "* Os pesos e bias iniciais foram sorteados e ser√£o ajustados pelo treinamento.\n",
        "* A fun√ß√£o de perda e o otimizador est√£o bem configurados para um problema bin√°rio pequeno (como o Iris).\n",
        "* Voc√™ est√° na etapa **‚Äúpr√©-treino‚Äù**, e o pr√≥ximo passo natural √©:\n",
        "\n",
        "  1. Rodar um loop de treinamento com `loss.backward()` e `optimizer.step()`,\n",
        "  2. Monitorar a perda decaindo com as √©pocas,\n",
        "  3. Ver a precis√£o aumentar no treino e no teste.\n",
        "\n",
        "üëâ Em linguagem simples:\n",
        "\n",
        "> ‚ÄúO modelo foi criado e est√° zerado. Agora vem a parte de ensinar ele a reconhecer a flor Versicolor.‚Äù üå∏üß†\n",
        "\n",
        "---\n",
        "\n",
        "Se voc√™ quiser, posso escrever o **loop de treinamento completo** usando esse modelo e mostrar como os pesos evoluem ao longo das √©pocas üìà.\n",
        "Quer que eu fa√ßa isso? üöÄ\n"
      ],
      "metadata": {
        "id": "AwwUpF5sg50Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 0) Dados (Iris ‚Üí bin√°rio: Versicolor=1, caso contr√°rio=0)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)\n",
        "\n",
        "# Split estratificado (80/20) e padroniza√ß√£o (boa pr√°tica p/ regress√£o log√≠stica)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True\n",
        ")\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 1) Modelo: regress√£o log√≠stica (Linear 4‚Üí1; Sigmoid embutida na loss)\n",
        "modelo = nn.Linear(4, 1)\n",
        "\n",
        "# 2) Fun√ß√£o de perda e otimizador\n",
        "funcao_perda = nn.BCEWithLogitsLoss()       # est√°vel numericamente (logits + BCE)\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)  # simples e funciona bem aqui\n",
        "\n",
        "# 3) Loop de treinamento\n",
        "EPOCHS = 500\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # --- modo treino ---\n",
        "    modelo.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    logits = modelo(X_train_t)              # sa√≠da linear\n",
        "    loss = funcao_perda(logits, y_train_t)  # BCE + Sigmoid (interno)\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # atualiza√ß√£o dos pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    # logging a cada 50 √©pocas\n",
        "    if epoch % 50 == 0 or epoch == 1:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(modelo(X_train_t))\n",
        "            preds_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (preds_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch:3d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 4) Avalia√ß√£o no TESTE\n",
        "modelo.eval()\n",
        "with torch.no_grad():\n",
        "    probs_te = torch.sigmoid(modelo(X_test_t))\n",
        "    preds_te = (probs_te >= 0.5).float()\n",
        "\n",
        "# m√©tricas no teste\n",
        "y_true = y_test_t.numpy().ravel()\n",
        "y_pred = preds_te.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "print(\"\\n=== M√©tricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acur√°cia : {acc:.3f}\")\n",
        "print(f\"Precis√£o : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "ynpcgUWAhdbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî o resultado que voc√™ obteve mostra um **modelo de regress√£o log√≠stica que aprendeu alguma coisa**, mas ainda **n√£o tem um desempenho preditivo muito bom**.\n",
        "Vamos analisar cada parte do output com calma üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. **Evolu√ß√£o do treinamento**\n",
        "\n",
        "```\n",
        "[  1/500] loss=0.6510  acc_train@0.5=0.575\n",
        "[ 50/500] loss=0.5371  acc_train@0.5=0.742\n",
        "[100/500] loss=0.5136  acc_train@0.5=0.725\n",
        "...\n",
        "[500/500] loss=0.4904  acc_train@0.5=0.742\n",
        "```\n",
        "\n",
        "‚úÖ **O que isso significa:**\n",
        "\n",
        "* A perda (loss) caiu de **0.6510 ‚Üí 0.4904**, o que mostra que o modelo **est√° aprendendo**.\n",
        "* A acur√°cia de treino subiu de **57,5% ‚Üí 74,2%**, estabilizando a partir da √©poca ~200.\n",
        "\n",
        "‚ö†Ô∏è **Mas observe:**\n",
        "\n",
        "* A loss **parou de cair significativamente** ap√≥s ~250 √©pocas.\n",
        "* A acur√°cia tamb√©m **estagnou em ~74%**.\n",
        "  ‚Üí Isso sugere que **o modelo atingiu um plat√¥**, ou seja, aprendeu o que conseguia com sua capacidade atual (apenas uma camada linear).\n",
        "\n",
        "üìå Interpreta√ß√£o:\n",
        "\n",
        "> O modelo captou alguns padr√µes, mas n√£o conseguiu capturar toda a complexidade dos dados.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 2. **Desempenho no conjunto de teste**\n",
        "\n",
        "```\n",
        "Acur√°cia : 0.633\n",
        "Precis√£o : 0.429\n",
        "Recall   : 0.300\n",
        "F1-score : 0.353\n",
        "```\n",
        "\n",
        "üëâ Esses n√∫meros contam a verdade sobre a capacidade preditiva:\n",
        "\n",
        "| M√©trica  | Valor | Interpreta√ß√£o                                                                   |\n",
        "| -------- | ----- | ------------------------------------------------------------------------------- |\n",
        "| Acur√°cia | 0.633 | S√≥ 63,3% de acertos no conjunto de teste.                                       |\n",
        "| Precis√£o | 0.429 | Quando prev√™ ‚ÄúVersicolor‚Äù, s√≥ acerta em 43% dos casos. Muitos falsos positivos. |\n",
        "| Recall   | 0.300 | S√≥ acerta 30% dos positivos reais. Muitos falsos negativos.                     |\n",
        "| F1-score | 0.353 | Baixo equil√≠brio entre precis√£o e recall.                                       |\n",
        "\n",
        "üìå **Resumo**:\n",
        "\n",
        "* O modelo erra bastante em ambas as classes.\n",
        "* Tem **baixa precis√£o e recall**, ent√£o **n√£o identifica bem a classe positiva (Versicolor)**.\n",
        "* Acur√°cia global baixa indica que **n√£o compensa bem nem prevendo tudo como 0**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 3. Diagn√≥stico\n",
        "\n",
        "| Sintoma                              | Causa prov√°vel                                                          |\n",
        "| ------------------------------------ | ----------------------------------------------------------------------- |\n",
        "| Plat√¥ de loss e acur√°cia             | Limita√ß√£o do modelo linear (pouca capacidade para padr√µes n√£o lineares) |\n",
        "| Precis√£o e recall baixos             | O modelo n√£o separa bem as classes                                      |\n",
        "| Gap entre treino (74%) e teste (63%) | Poss√≠vel overfitting leve ou m√° generaliza√ß√£o                           |\n",
        "| Treinamento estabilizado cedo        | Talvez LR alta demais, sem refinamento fino                             |\n",
        "\n",
        "üëâ Em resumo:\n",
        "\n",
        "> O modelo **aprendeu algo**, mas n√£o tem poder preditivo forte.\n",
        "> Isso √© t√≠pico de modelos lineares simples em problemas com **fronteiras de decis√£o mais complexas**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ 4. Como melhorar significativamente\n",
        "\n",
        "### üî∏ **1. Normalizar/Padronizar os dados**\n",
        "\n",
        "Voc√™ j√° pode estar fazendo isso ‚Äî mas se n√£o, √© essencial para regress√£o log√≠stica.\n",
        "\n",
        "### üî∏ **2. Aumentar capacidade do modelo**\n",
        "\n",
        "Adicionar uma camada escondida simples:\n",
        "\n",
        "```python\n",
        "modelo = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)\n",
        ")\n",
        "```\n",
        "\n",
        "‚û°Ô∏è Isso permite aprender **padr√µes n√£o lineares**, melhorando recall e precis√£o.\n",
        "\n",
        "### üî∏ **3. Otimizador mais eficiente**\n",
        "\n",
        "Trocar de `SGD` para `Adam`:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.01)\n",
        "```\n",
        "\n",
        "‚û°Ô∏è Adam converge mais r√°pido e costuma escapar melhor de plat√¥s.\n",
        "\n",
        "### üî∏ **4. Ajustar learning rate**\n",
        "\n",
        "`lr=0.1` √© alto para alguns problemas. Tente `0.01` ou `0.005` para treinos mais suaves.\n",
        "\n",
        "### üî∏ **5. Regulariza√ß√£o leve**\n",
        "\n",
        "Adicionar `weight_decay` no otimizador pode evitar overfitting e melhorar generaliza√ß√£o:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "```\n",
        "\n",
        "### üî∏ **6. Tuning de threshold**\n",
        "\n",
        "Ajustar o limiar de decis√£o pode **melhorar precis√£o ou recall**, mas isso **n√£o resolve** falta de aprendizado.\n",
        "‚Üí Primeiro melhore o modelo.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä 5. Comparando com um bom modelo (refer√™ncia)\n",
        "\n",
        "| M√©trica         | Atual modelo | Modelo bom (esperado) |\n",
        "| --------------- | ------------ | --------------------- |\n",
        "| Loss final      | 0.49         | 0.05 ‚Äì 0.2            |\n",
        "| Acur√°cia treino | 0.742        | 0.90+                 |\n",
        "| Acur√°cia teste  | 0.633        | 0.85‚Äì0.97             |\n",
        "| Precis√£o        | 0.429        | 0.90+                 |\n",
        "| Recall          | 0.300        | 0.85+                 |\n",
        "| F1              | 0.353        | 0.90+                 |\n",
        "\n",
        "üìå Esse tipo de diferen√ßa mostra claramente que o modelo atual ainda √© **fraco** e precisa ser aprimorado.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Conclus√£o\n",
        "\n",
        "‚ùå **N√£o √© um bom modelo preditivo** no estado atual.\n",
        "‚úÖ **Mas √© um modelo que aprendeu alguma coisa**, e com pequenos ajustes ‚Äî especialmente na arquitetura e otimiza√ß√£o ‚Äî ele pode se tornar bom.\n",
        "\n",
        "**Problema:** modelo linear limitado.\n",
        "**Solu√ß√£o:** aumentar capacidade, melhorar otimiza√ß√£o e calibrar.\n",
        "\n",
        "> üß† ‚ÄúVoc√™ est√° com um motor 1.0 tentando correr uma corrida de F1 ‚Äî √© hora de turbinar um pouco.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "Se voc√™ quiser, posso adaptar seu c√≥digo atual com:\n",
        "\n",
        "* uma camada escondida simples,\n",
        "* Adam,\n",
        "* LR menor,\n",
        "* e mostrar a compara√ß√£o de m√©tricas antes e depois.\n",
        "\n",
        "Quer que eu monte essa vers√£o melhorada agora? üöÄ‚ú®\n"
      ],
      "metadata": {
        "id": "Yfc6ujtWiLoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Iris bin√°rio (Versicolor=1) ‚Äî MLP + Adam + padroniza√ß√£o + threshold tuning\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split estratificado + padroniza√ß√£o (fit no treino, transform no teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, stratify=y, shuffle=True\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 3) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo ‚Äî MLP simples (mais capacidade que regress√£o log√≠stica)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)   # logits\n",
        ")\n",
        "\n",
        "# 5) Loss e Otimizador (Adam + L2)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 6) Treino\n",
        "EPOCHS = 800\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0 or epoch == 1:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            preds_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (preds_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch:3d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 7) Avalia√ß√£o no teste (threshold=0.5)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "y_pred05 = (test_probs >= 0.5).astype(float)\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "acc05, prec05, rec05, f105, cm05 = metrics(y_true, y_pred05)\n",
        "try:\n",
        "    auc = roc_auc_score(y_true, test_probs)\n",
        "except Exception:\n",
        "    auc = None\n",
        "\n",
        "print(\"\\n=== TESTE @ threshold=0.5 ===\")\n",
        "print(f\"Acur√°cia : {acc05:.3f}\")\n",
        "print(f\"Precis√£o : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", cm05)\n",
        "if auc is not None:\n",
        "    print(f\"AUC-ROC  : {auc:.3f}\")\n",
        "\n",
        "# 8) Varredura de limiar (max F1)\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc, prec, rec, f1, cm = metrics(y_true, y_pred_t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(\"\\n=== Varredura de limiar ‚Äî top 5 por F1 (TESTE) ===\")\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acur√°cia  : {best['acc']:.3f}\")\n",
        "print(f\"Precis√£o  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", best['cm'])\n",
        "if auc is not None:\n",
        "    print(f\"AUC-ROC  : {auc:.3f}  (n√£o depende do threshold)\")\n"
      ],
      "metadata": {
        "id": "0AL11Fh_iOR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî esse resultado √© **muito diferente** do seu modelo linear anterior e mostra que agora voc√™ realmente tem um **modelo preditivo de alta performance**.\n",
        "Vamos analisar por etapas para entender o que aconteceu e **por que esse modelo √© bom** üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. Evolu√ß√£o do treinamento\n",
        "\n",
        "```\n",
        "[  1/800] loss=0.7672  acc_train@0.5=0.483\n",
        "[100/800] loss=0.0837  acc_train@0.5=0.975\n",
        "[200/800] loss=0.0461  acc_train@0.5=0.983\n",
        "...\n",
        "[800/800] loss=0.0298  acc_train@0.5=0.983\n",
        "```\n",
        "\n",
        "‚úÖ **Interpreta√ß√£o:**\n",
        "\n",
        "* A perda caiu de **0.767 ‚Üí 0.0298**, ou seja, uma **redu√ß√£o muito grande e consistente** ‚Äî o modelo aprendeu a mapear bem os padr√µes do dataset.\n",
        "* A acur√°cia de treino subiu de **48,3% para 98,3%**, estabilizando cedo (por volta da √©poca 200).\n",
        "* A curva de loss √© suave, sem oscila√ß√µes ‚Üí **boa converg√™ncia com Adam**.\n",
        "* O modelo **n√£o est√° overfittando de forma preocupante**, porque o desempenho no teste tamb√©m √© alto (ver abaixo).\n",
        "\n",
        "üìå **Conclus√£o:**\n",
        "O modelo conseguiu **aprender a estrutura do problema** e manteve estabilidade durante o treino ‚Äî isso √© um forte indicador de um bom treinamento.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 2. Desempenho no conjunto de teste (threshold = 0.5)\n",
        "\n",
        "```\n",
        "Acur√°cia : 0.967\n",
        "Precis√£o : 1.000\n",
        "Recall   : 0.900\n",
        "F1-score : 0.947\n",
        "Matriz de confus√£o:\n",
        " [[20  0]\n",
        " [ 1  9]]\n",
        "AUC-ROC  : 0.995\n",
        "```\n",
        "\n",
        "| M√©trica  | Valor | Interpreta√ß√£o                                                                 |\n",
        "| -------- | ----- | ----------------------------------------------------------------------------- |\n",
        "| Acur√°cia | 0.967 | 96,7% de acertos ‚Äî excelente para uma tarefa de classifica√ß√£o bin√°ria pequena |\n",
        "| Precis√£o | 1.000 | Nenhum falso positivo ‚Äî modelo super confi√°vel para positivos                 |\n",
        "| Recall   | 0.900 | Acerta 90% dos casos positivos (falhou em apenas 1)                           |\n",
        "| F1-score | 0.947 | Equil√≠brio excelente entre precis√£o e recall                                  |\n",
        "| AUC-ROC  | 0.995 | Separa√ß√£o quase perfeita entre classes                                        |\n",
        "\n",
        "üìä **Matriz de confus√£o**:\n",
        "\n",
        "| Real \\ Predito | 0  | 1 |\n",
        "| -------------- | -- | - |\n",
        "| 0 (negativo)   | 20 | 0 |\n",
        "| 1 (positivo)   | 1  | 9 |\n",
        "\n",
        "üëâ Isso mostra:\n",
        "\n",
        "* **20 acertos em 20 negativos**\n",
        "* **9 acertos em 10 positivos**\n",
        "* **0 falsos positivos**\n",
        "* Apenas **1 falso negativo**\n",
        "\n",
        "üìå **Conclus√£o:**\n",
        "Esse √© **um modelo altamente discriminativo**, com excelente equil√≠brio entre sensibilidade e precis√£o ‚Äî praticamente perfeito para este problema.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 3. Varredura de threshold\n",
        "\n",
        "```\n",
        "Top 5 por F1 (threshold 0.15‚Äì0.35): F1 = 0.947\n",
        "```\n",
        "\n",
        "üëâ O F1 ficou **id√™ntico** para todos esses limiares.\n",
        "‚û°Ô∏è Isso indica que:\n",
        "\n",
        "* As probabilidades previstas est√£o **muito bem separadas entre classes** (n√£o h√° valores amb√≠guos pr√≥ximos de 0.5).\n",
        "* O modelo est√° **bem calibrado** ‚Äî ele n√£o depende fortemente de um threshold ‚Äúm√°gico‚Äù para ter bom desempenho.\n",
        "* A estabilidade do F1 em v√°rios thresholds refor√ßa que a **confian√ßa do modelo nas predi√ß√µes √© alta**.\n",
        "\n",
        "üìå **Conclus√£o:**\n",
        "Modelo bem calibrado + margens de decis√£o largas = √≥timo comportamento preditivo.\n",
        "\n",
        "---\n",
        "\n",
        "## üìä 4. Compara√ß√£o com o modelo anterior (linear)\n",
        "\n",
        "| M√©trica         | Modelo Linear | Modelo MLP (atual) |\n",
        "| --------------- | ------------- | ------------------ |\n",
        "| Loss final      | 0.49          | **0.0298** ‚úÖ       |\n",
        "| Acur√°cia treino | 0.742         | **0.983** ‚úÖ        |\n",
        "| Acur√°cia teste  | 0.633         | **0.967** ‚úÖ        |\n",
        "| Precis√£o        | 0.429         | **1.000** ‚úÖ        |\n",
        "| Recall          | 0.300         | **0.900** ‚úÖ        |\n",
        "| F1              | 0.353         | **0.947** ‚úÖ        |\n",
        "| AUC-ROC         | ‚Äî             | **0.995** ‚úÖ        |\n",
        "\n",
        "üìå Agora seu modelo:\n",
        "\n",
        "* **Generaliza muito melhor**,\n",
        "* **Aprende padr√µes n√£o lineares** gra√ßas √† camada escondida,\n",
        "* **Classifica com alta confian√ßa** (precis√£o perfeita),\n",
        "* E tem recall alto, ou seja, **identifica quase todos os casos positivos**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß∞ 5. Diagn√≥stico final\n",
        "\n",
        "| Ponto forte               | Evid√™ncia                                           |\n",
        "| ------------------------- | --------------------------------------------------- |\n",
        "| Aprendizado efetivo       | Queda forte e est√°vel na loss                       |\n",
        "| Alta capacidade preditiva | Acur√°cia 96,7%, F1 0,947, AUC 0,995                 |\n",
        "| Baixo overfitting         | Acur√°cia treino e teste pr√≥ximas                    |\n",
        "| Alta calibragem           | F1 est√°vel para diferentes thresholds               |\n",
        "| Modelo leve               | Apenas uma hidden layer ‚Äî baixo custo computacional |\n",
        "\n",
        "‚ö†Ô∏è **Poss√≠vel ajuste** (se fosse um caso real):\n",
        "\n",
        "* Aumentar um pouco o recall (de 0.90 para 1.0) ajustando o threshold para **abaixo de 0.5** (ex.: 0.15 j√° est√° √≥timo).\n",
        "* Avaliar com valida√ß√£o cruzada se o dataset for pequeno ‚Äî s√≥ para garantir robustez.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Conclus√£o Final\n",
        "\n",
        "üìå **Sim, agora voc√™ tem um excelente modelo preditivo.**\n",
        "\n",
        "* **Aprendeu bem**, sem overfitting,\n",
        "* **Alta precis√£o e recall**,\n",
        "* **Alta AUC** indica separa√ß√£o clara das classes,\n",
        "* E **boa estabilidade com diferentes thresholds**.\n",
        "\n",
        "üëâ Em linguagem simples:\n",
        "\n",
        "> üß† ‚ÄúAntes seu modelo chutava bem. Agora ele est√° acertando de verdade.‚Äù ‚ö°üå∏\n",
        "\n",
        "---\n",
        "\n",
        "Se voc√™ quiser, posso montar um gr√°fico com:\n",
        "\n",
        "* **Curva ROC + AUC**,\n",
        "* **Distribui√ß√£o das probabilidades por classe**,\n",
        "* **Curva Precision‚ÄìRecall**,\n",
        "\n",
        "para **visualizar graficamente a qualidade desse classificador**. Quer que eu gere esses gr√°ficos? üìà‚ú®\n"
      ],
      "metadata": {
        "id": "-vVtGdh3jd7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execu√ß√£o do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treino\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad() # reseta gradiente sen√£o acumula\n",
        "    outputs = modelo(X)\n",
        "    loss = funcao_perda(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"√âpoca [{epoch+1}/100], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}