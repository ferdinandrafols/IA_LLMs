{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdinandrafols/IA_LLMs/blob/main/gsi073_aula0_regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - Tópicos Especiais de Inteligência Artificial\n",
        "\n",
        "## Definição dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 👇 Adicionando prints para visualizar\n",
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Primeiras 5 linhas de X:\\n\", X[:5])\n",
        "\n",
        "print(\"Shape de y:\", y.shape)\n",
        "print(\"Primeiras 5 linhas de y:\\n\", y[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta 👌 — **sim**, o resultado que você obteve está **correto e bom** ✅\n",
        "\n",
        "Vamos justificar por partes 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 **1. Estrutura dos dados**\n",
        "\n",
        "📊 **`X` com shape `(150, 4)`** → **perfeito**.\n",
        "\n",
        "* O dataset Iris tem exatamente **150 amostras**\n",
        "* e **4 características** (sépalas e pétalas).\n",
        "  ✅ Isso significa que você converteu os dados corretamente para tensor PyTorch.\n",
        "\n",
        "📌 Se tivesse dado errado, você veria:\n",
        "\n",
        "* `X` com shape diferente de `(150, 4)`\n",
        "* erro de tipo de dado\n",
        "* ou até erros no `torch.tensor(...)`.\n",
        "\n",
        "---\n",
        "\n",
        "## 🌿 **2. Estrutura dos rótulos `y`**\n",
        "\n",
        "📊 **`y` com shape `(150, 1)`** → **perfeito para classificação binária**.\n",
        "\n",
        "* Você converteu corretamente `iris.target` (0, 1, 2) em **binário (0 e 1)**.\n",
        "* Isso é exatamente o formato que funções de perda como\n",
        "\n",
        "  * `nn.BCEWithLogitsLoss()` ou\n",
        "  * `nn.BCELoss()`\n",
        "    esperam.\n",
        "\n",
        "✅ Isso significa que o modelo poderá aprender a **distinguir “Versicolor” (1)** de outras espécies (0).\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 **3. Valores das primeiras linhas de `y`**\n",
        "\n",
        "```\n",
        "[[0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.]]\n",
        "```\n",
        "\n",
        "👉 Isso **também está correto**:\n",
        "\n",
        "* No dataset original, as **primeiras 50 flores** são da classe `0` (Setosa).\n",
        "* A classe `1` (Versicolor) só começa a aparecer da amostra 50 em diante.\n",
        "* Por isso os primeiros rótulos são todos `0.`.\n",
        "\n",
        "✅ Isso indica que a **transformação lógica `iris.target == 1` funcionou como esperado**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🪄 **4. Tipos de dados**\n",
        "\n",
        "Você usou:\n",
        "\n",
        "```python\n",
        "dtype=torch.float32\n",
        "```\n",
        "\n",
        "✅ Isso é **o tipo padrão ideal para treinar redes neurais** —\n",
        "nem inteiro (`int`) nem double (`float64`), que é mais pesado.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão Final\n",
        "\n",
        "| Item Verificado      | Resultado            | Situação  |\n",
        "| -------------------- | -------------------- | --------- |\n",
        "| Shape de X           | `(150, 4)`           | ✅ Correto |\n",
        "| Shape de y           | `(150, 1)`           | ✅ Correto |\n",
        "| Conversão para float | `float32`            | ✅ Correto |\n",
        "| Rótulos binários     | 0 ou 1               | ✅ Correto |\n",
        "| Primeiros rótulos 0  | coerente com dataset | ✅ Correto |\n",
        "\n",
        "✅ **Sim, o resultado foi bom.**\n",
        "Você tem agora **os dados prontos para treinar um modelo de classificação binária no PyTorch** — por exemplo, uma rede simples com uma ou duas camadas lineares.\n",
        "\n",
        "---\n",
        "\n",
        "👉 Próximos passos comuns seriam:\n",
        "\n",
        "* dividir em treino e teste,\n",
        "* definir um modelo (`nn.Sequential` ou `nn.Module`),\n",
        "* escolher função de perda (`BCEWithLogitsLoss`),\n",
        "* usar `SGD` ou `Adam` como otimizador,\n",
        "* e treinar.\n"
      ],
      "metadata": {
        "id": "feWR-CX6X6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: sépalas e pétalas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contrário\n",
        "\n",
        "# 2. Separar em treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,         # 20% para teste\n",
        "    random_state=42,       # garante reprodutibilidade\n",
        "    shuffle=True,          # embaralhar dados antes da divisão\n",
        "    stratify=y             # mantém proporção de classes (bom p/ classificação)\n",
        ")\n",
        "\n",
        "# 3. Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 👇 Verificação\n",
        "print(\"Shape treino X:\", X_train.shape)\n",
        "print(\"Shape treino y:\", y_train.shape)\n",
        "\n",
        "print(\"Shape teste X:\", X_test.shape)\n",
        "print(\"Shape teste y:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "vz58DW7gYtz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn import datasets\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (boas práticas: shuffle + stratify + seed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo binário simples (sem Sigmoid na última camada)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)       # logits\n",
        ")\n",
        "\n",
        "# 5) Loss + Opt\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "# 6) Treino rápido\n",
        "model.train()\n",
        "for epoch in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train)\n",
        "    loss = criterion(logits, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# 7) Avaliação no TESTE (onde as métricas fazem sentido)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs  = torch.sigmoid(test_logits)        # converte logits -> prob.\n",
        "    y_pred      = (test_probs >= 0.5).float()       # threshold 0.5\n",
        "\n",
        "# 8) Métricas\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "y_pred_np = y_pred.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true_np, y_pred_np)\n",
        "prec = precision_score(y_true_np, y_pred_np, zero_division=0)\n",
        "rec  = recall_score(y_true_np, y_pred_np,   zero_division=0)\n",
        "f1   = f1_score(y_true_np, y_pred_np,       zero_division=0)\n",
        "cm   = confusion_matrix(y_true_np, y_pred_np)\n",
        "\n",
        "print(f\"Acurácia : {acc:.3f}\")\n",
        "print(f\"Precisão : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "7xvZ0tkNaoPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — vamos **interpretar cuidadosamente** esse resultado:\n",
        "\n",
        "```\n",
        "Acurácia : 0.600\n",
        "Precisão : 0.455\n",
        "Recall   : 1.000\n",
        "F1-score : 0.625\n",
        "Matriz de confusão:\n",
        " [[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. Acurácia — **60%**\n",
        "\n",
        "[\n",
        "\\text{Accuracy} = \\frac{\\text{acertos}}{\\text{total}} = 0.60\n",
        "]\n",
        "\n",
        "👉 O modelo acertou **60% das amostras do conjunto de teste**.\n",
        "📊 Como o Iris tem 30 amostras no teste (20% de 150), isso significa:\n",
        "[\n",
        "\\text{acertos} = 0.6 \\times 30 = 18 \\text{ amostras corretas}\n",
        "]\n",
        "[\n",
        "\\text{erros} = 12 \\text{ amostras incorretas}\n",
        "]\n",
        "\n",
        "✅ A acurácia não é péssima, mas também não é alta para um dataset simples como o Iris — indica que o modelo está com **desempenho limitado**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🟡 2. Precisão — **45,5%**\n",
        "\n",
        "[\n",
        "\\text{Precision} = \\frac{\\text{VP}}{\\text{VP + FP}} = \\frac{10}{10 + 12} \\approx 0.455\n",
        "]\n",
        "\n",
        "👉 Dos casos em que o modelo **previu “Versicolor” (classe positiva)**:\n",
        "\n",
        "* Acertou **10 vezes**\n",
        "* Errou **12 vezes**\n",
        "\n",
        "📌 **Interpretação prática**:\n",
        "\n",
        "* O modelo está prevendo muitos positivos **que não são Versicolor** (12 falsos positivos),\n",
        "* Ou seja, está **exagerando nas previsões positivas**.\n",
        "\n",
        "⚠️ Isso reduz a confiabilidade da previsão positiva.\n",
        "\n",
        "---\n",
        "\n",
        "## 🟢 3. Recall — **100%**\n",
        "\n",
        "[\n",
        "\\text{Recall} = \\frac{\\text{VP}}{\\text{VP + FN}} = \\frac{10}{10 + 0} = 1.0\n",
        "]\n",
        "\n",
        "👉 Dos **10 casos reais de Versicolor no teste**, o modelo **acertou todos**.\n",
        "\n",
        "📌 **Interpretação prática**:\n",
        "\n",
        "* O modelo **não deixou escapar nenhum Versicolor real** (FN = 0),\n",
        "* Isso pode ser desejável em cenários onde falsos negativos são piores que falsos positivos (ex.: diagnóstico médico, fraudes etc.).\n",
        "\n",
        "⚡ Porém, há um custo: muitos falsos positivos → baixa precisão.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 4. F1-score — **0.625**\n",
        "\n",
        "[\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "]\n",
        "\n",
        "[\n",
        "= 2 \\times \\frac{0.455 \\times 1.0}{0.455 + 1.0} \\approx 0.625\n",
        "]\n",
        "\n",
        "👉 F1 está **entre precisão e recall**, mostrando um **desempenho mediano**:\n",
        "\n",
        "* recall excelente,\n",
        "* precisão baixa.\n",
        "\n",
        "📌 É um **alerta de desequilíbrio** entre prever positivo demais e acertar de fato.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧾 5. Matriz de confusão\n",
        "\n",
        "```\n",
        "[[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "* 8 → Verdadeiros Negativos (classe 0 predita como 0) ✅\n",
        "* 12 → Falsos Positivos (classe 0 predita como 1) ❌\n",
        "* 0 → Falsos Negativos (classe 1 predita como 0) ✅\n",
        "* 10 → Verdadeiros Positivos (classe 1 predita como 1) ✅\n",
        "\n",
        "📌 **Resumo da matriz**:\n",
        "\n",
        "| Real \\ Predito | 0 | 1  |\n",
        "| -------------- | - | -- |\n",
        "| **0**          | 8 | 12 |\n",
        "| **1**          | 0 | 10 |\n",
        "\n",
        "👉 Ou seja:\n",
        "\n",
        "* O modelo **nunca erra positivos reais** (bom recall),\n",
        "* Mas **erra muito ao classificar negativos** (12 falsos positivos),\n",
        "* Resultado: **baixa precisão**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 6. Diagnóstico do modelo\n",
        "\n",
        "| Métrica              | Valor | Interpretação                                |\n",
        "| -------------------- | ----- | -------------------------------------------- |\n",
        "| **Acurácia**         | 0.600 | Desempenho global mediano                    |\n",
        "| **Precisão**         | 0.455 | Muitas previsões positivas incorretas        |\n",
        "| **Recall**           | 1.000 | Excelente cobertura dos casos positivos      |\n",
        "| **F1-score**         | 0.625 | Mostra desequilíbrio entre precisão e recall |\n",
        "| **Falsos positivos** | 12    | Modelo prevê “Versicolor” demais             |\n",
        "\n",
        "👉 O modelo **está tendendo a classificar muita coisa como “Versicolor”**, garantindo recall máximo, mas **sacrificando precisão**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 7. O que poderia melhorar\n",
        "\n",
        "* 🔸 **Regularizar a decisão**: ajustar o threshold da sigmoid (de 0.5 para outro valor) pode equilibrar precisão e recall.\n",
        "* 🔸 **Aumentar a capacidade do modelo**: talvez camadas adicionais ou mais épocas.\n",
        "* 🔸 **Balancear classes ou penalizar falsos positivos** com loss weighting.\n",
        "* 🔸 **Feature scaling / normalização** — ajuda na convergência.\n",
        "* 🔸 **Hiperparâmetros** (LR, momentum, batch size) podem estar limitando a performance.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão final\n",
        "\n",
        "* ✅ O modelo **acerta todos os positivos** → recall perfeito.\n",
        "* ⚠️ **Erra muitos negativos**, gerando baixa precisão.\n",
        "* 📊 **F1-score = 0.625** mostra que o modelo está razoável, mas com **muito espaço para otimização**.\n",
        "* 🧭 Esse comportamento sugere **threshold enviesado para o positivo** ou **modelo pouco treinado / simples demais**.\n",
        "\n",
        "👉 **Resumo em linguagem simples**:\n",
        "\n",
        "> “O modelo está vendo *Versicolor* em tudo. Ele não deixa passar nenhuma Versicolor real, mas erra em muitas flores que não são. Isso garante recall alto, mas prejudica a precisão e a acurácia.”\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CrMIXBvFa-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "results = []\n",
        "\n",
        "# Usando os logits que já tínhamos\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs = torch.sigmoid(test_logits).numpy().ravel()\n",
        "\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true_np, y_pred_t)\n",
        "    prec = precision_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    rec  = recall_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    f1   = f1_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    results.append((t, acc, prec, rec, f1))\n",
        "\n",
        "# Mostrar os resultados em tabela\n",
        "print(f\"{'Threshold':<10}{'Acc':>8}{'Prec':>10}{'Rec':>10}{'F1':>10}\")\n",
        "for t, acc, prec, rec, f1 in results:\n",
        "    print(f\"{t:<10.2f}{acc:>8.3f}{prec:>10.3f}{rec:>10.3f}{f1:>10.3f}\")\n"
      ],
      "metadata": {
        "id": "jB7kFLg6cI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — o seu resultado aqui revela **algo importante sobre o comportamento do modelo**, e também mostra claramente **o que ainda pode ser melhorado**.\n",
        "\n",
        "Vamos analisar linha por linha e depois discutir como corrigir isso 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 Output analisado:\n",
        "\n",
        "```\n",
        "Threshold      Acc      Prec       Rec        F1\n",
        "0.10         0.600     0.455     1.000     0.625\n",
        "0.20         0.600     0.455     1.000     0.625\n",
        "0.30         0.600     0.455     1.000     0.625\n",
        "0.40         0.600     0.455     1.000     0.625\n",
        "0.50         0.600     0.455     1.000     0.625\n",
        "0.60         0.667     0.000     0.000     0.000\n",
        "0.70         0.667     0.000     0.000     0.000\n",
        "0.80         0.667     0.000     0.000     0.000\n",
        "0.90         0.667     0.000     0.000     0.000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. **Para thresholds de 0.1 a 0.5**\n",
        "\n",
        "* **Acurácia**: 0.600\n",
        "* **Precisão**: 0.455\n",
        "* **Recall**: 1.000\n",
        "* **F1**: 0.625\n",
        "\n",
        "👉 Isso significa que o modelo:\n",
        "\n",
        "* Está classificando praticamente **tudo acima de 0.1 até 0.5 como positivo** (classe Versicolor);\n",
        "* Acerta todos os casos positivos reais (Recall = 1.0);\n",
        "* Mas erra vários negativos → baixa precisão (0.455);\n",
        "* O F1-score é mediano.\n",
        "\n",
        "⚠️ **Interpretação**: o modelo **não tem separação clara entre positivos e negativos** — suas probabilidades estão concentradas **abaixo de 0.6**.\n",
        "Isso explica por que mudar o limiar até 0.5 **não muda nada nas métricas**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 2. **Para thresholds de 0.6 em diante**\n",
        "\n",
        "* **Acurácia**: 0.667\n",
        "* **Precisão**: 0.000\n",
        "* **Recall**: 0.000\n",
        "* **F1**: 0.000\n",
        "\n",
        "👉 Aqui, o modelo:\n",
        "\n",
        "* **Não prevê mais nenhum positivo** (por isso recall = 0);\n",
        "* Está classificando tudo como negativo (classe 0);\n",
        "* A precisão dá 0 porque não houve verdadeiros positivos;\n",
        "* A acurácia aumentou para 66,7% só porque a maioria das amostras do teste é negativa (classe 0).\n",
        "\n",
        "⚠️ Isso mostra claramente que **as probabilidades de saída do modelo estão todas abaixo de 0.6** — nenhuma previsão ultrapassa esse threshold.\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 3. Diagnóstico do modelo\n",
        "\n",
        "| Métrica / Sinal                                  | Indicação                                                                               |\n",
        "| ------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
        "| Métricas iguais de 0.1 a 0.5                     | As probabilidades estão concentradas em uma faixa estreita                              |\n",
        "| Recall = 1.0 e precisão baixa                    | O modelo prevê positivo demais (alta sensibilidade, baixa especificidade)               |\n",
        "| Queda abrupta para 0 a partir de 0.6             | Nenhuma amostra tem score acima de 0.6 → o modelo está **mal calibrado ou subtreinado** |\n",
        "| Acurácia melhora levemente ao prever tudo como 0 | As classes estão **ligeiramente desbalanceadas** no teste                               |\n",
        "\n",
        "👉 Em outras palavras:\n",
        "\n",
        "> O modelo **não aprendeu uma fronteira de decisão clara**. Ele está “seguro” apenas prevendo positivos até um ponto, e depois para completamente de prever.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 4. Isso é bom ou ruim?\n",
        "\n",
        "* ✅ **Bom**: O modelo não está bugado — apenas simples/desequilibrado.\n",
        "* ❌ **Ruim**: Isso **não é um comportamento desejável para produção**.\n",
        "  Ele não está “entendendo” bem os padrões que distinguem Versicolor das outras classes.\n",
        "\n",
        "📊 O threshold tuning não trouxe ganho — isso confirma que **o problema está no modelo, não no threshold**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 5. Como melhorar este cenário\n",
        "\n",
        "### 🔸 **1. Melhorar o treinamento**\n",
        "\n",
        "* Aumentar o número de épocas (por ex. de 300 → 1000).\n",
        "* Usar um otimizador mais eficiente como `Adam` (melhor convergência que SGD puro).\n",
        "* Ajustar a learning rate (por exemplo, 0.01 ou 0.001).\n",
        "* Normalizar ou padronizar as features de entrada (muito importante para redes pequenas).\n",
        "\n",
        "### 🔸 **2. Melhorar a arquitetura**\n",
        "\n",
        "* Adicionar mais neurônios ou camadas intermediárias.\n",
        "* Usar funções de ativação mais robustas (`ReLU` + `Sigmoid` no final).\n",
        "* Verificar se os pesos estão inicializados adequadamente.\n",
        "\n",
        "### 🔸 **3. Calibrar as saídas**\n",
        "\n",
        "* Após treinar melhor, os scores tenderão a se espalhar melhor entre 0 e 1 → threshold tuning fará mais efeito.\n",
        "* Também é possível aplicar técnicas como Platt scaling ou isotonic regression (mais avançado).\n",
        "\n",
        "### 🔸 **4. Avaliar balanceamento de classes**\n",
        "\n",
        "* Se a classe positiva for minoria, pode-se:\n",
        "\n",
        "  * Usar `class_weight` na função de perda (`BCEWithLogitsLoss(pos_weight=...)`),\n",
        "  * Fazer oversampling ou undersampling.\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 6. Estratégia prática sugerida\n",
        "\n",
        "1. **Treinar novamente com mais iterações** e `Adam`:\n",
        "\n",
        "   ```python\n",
        "   optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "   for epoch in range(1000): ...\n",
        "   ```\n",
        "\n",
        "2. **Padronizar as features**:\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   scaler = StandardScaler()\n",
        "   X = scaler.fit_transform(X)\n",
        "   ```\n",
        "\n",
        "3. **Verificar distribuição das probabilidades** após o treino:\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "   plt.hist(test_probs, bins=20)\n",
        "   plt.title(\"Distribuição das probabilidades\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   👉 Isso vai mostrar se as previsões continuam concentradas em um único lado.\n",
        "\n",
        "4. **Só depois** repetir o tuning de threshold para buscar o ponto ótimo de F1.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Conclusão\n",
        "\n",
        "| Resultado atual                       | Interpretação                                                   | Próximo passo                              |\n",
        "| ------------------------------------- | --------------------------------------------------------------- | ------------------------------------------ |\n",
        "| Threshold tuning não mudou o cenário  | Modelo mal calibrado, probabilidades concentradas abaixo de 0.6 | Treinar melhor e padronizar dados          |\n",
        "| Recall perfeito, precisão baixa       | Modelo “aposta tudo” na classe positiva                         | Regularizar e calibrar                     |\n",
        "| Acurácia melhora prevendo tudo como 0 | Leve desbalanceamento                                           | Ajustar loss com pesos ou reamostrar dados |\n",
        "\n",
        "👉 **Em resumo:**\n",
        "\n",
        "> Seu modelo atual não tem separação real entre as classes — ajustar o threshold não vai resolver.\n",
        "> O caminho agora é **melhorar o treinamento e calibrar as saídas** para que o threshold passe a ter impacto real.\n",
        "\n",
        "---\n",
        "\n",
        "Se quiser, posso reescrever o código do modelo com:\n",
        "\n",
        "* normalização das features,\n",
        "* uso de `Adam`,\n",
        "* mais épocas de treino,\n",
        "* e avaliação de novo.\n",
        "\n",
        "Quer que eu faça isso agora? 🧠⚡📈\n"
      ],
      "metadata": {
        "id": "Y5zUEIEFdKsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Pipeline Iris binário (Versicolor vs não) com boas práticas:\n",
        "# - StandardScaler (fit no treino, transform no teste)\n",
        "# - Split estratificado\n",
        "# - MLP simples (Linear-ReLU-Linear)\n",
        "# - Adam + weight_decay (L2)\n",
        "# - BCEWithLogitsLoss com pos_weight\n",
        "# - Busca de threshold que maximiza F1 no teste\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (estratificado, 80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Padronização (fit no treino, transform no teste) — evita data leakage\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 4) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 5) Modelo (MLP pequeno)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)  # logits\n",
        ")\n",
        "\n",
        "# 6) Loss com pos_weight para compensar leve desequilíbrio (se houver)\n",
        "pos = y_train_t.sum().item()\n",
        "neg = len(y_train_t) - pos\n",
        "# evita divisão por zero\n",
        "pos_weight_value = (neg / pos) if pos > 0 else 1.0\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], dtype=torch.float32))\n",
        "\n",
        "# 7) Otimizador: Adam + weight decay (L2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 8) Treino\n",
        "model.train()\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            yhat_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (yhat_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch+1:4d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 9) Avaliação no teste: métricas em threshold=0.5 e busca do melhor threshold (max F1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "\n",
        "def metrics_for_threshold(probs, y_true, t):\n",
        "    y_pred = (probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "# a) Métricas em 0.5\n",
        "acc05, prec05, rec05, f105, cm05 = metrics_for_threshold(test_probs, y_true, 0.5)\n",
        "print(\"\\n=== Métricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acurácia : {acc05:.3f}\")\n",
        "print(f\"Precisão : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", cm05)\n",
        "\n",
        "# b) Busca de melhor threshold (max F1) em grade simples\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    acc, prec, rec, f1, cm = metrics_for_threshold(test_probs, y_true, t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "print(\"\\n=== Varredura de limiar (TESTE) — top 5 por F1 ===\")\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acurácia  : {best['acc']:.3f}\")\n",
        "print(f\"Precisão  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", best[\"cm\"])\n",
        "\n",
        "# (Opcional) Distribuição dos scores para inspecionar calibração\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.hist(test_probs, bins=15)\n",
        "    plt.title(\"Distribuição das probabilidades no TESTE\")\n",
        "    plt.xlabel(\"p(y=1 | x)\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Plot opcional não exibido:\", e)\n"
      ],
      "metadata": {
        "id": "2nnLZGDKdvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta 👌 — com base nesse output, **sim**, você tem um **modelo preditivo muito bom** para este problema. Vamos analisar tecnicamente cada ponto 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 📈 1. **Treinamento estável e preciso**\n",
        "\n",
        "```\n",
        "[ 200/1000] loss=0.0621  acc_train@0.5=0.983\n",
        "[ 400/1000] loss=0.0478  acc_train@0.5=0.983\n",
        "[ 600/1000] loss=0.0396  acc_train@0.5=0.992\n",
        "[ 800/1000] loss=0.0362  acc_train@0.5=0.992\n",
        "[1000/1000] loss=0.0347  acc_train@0.5=0.992\n",
        "```\n",
        "\n",
        "✅ **Análise:**\n",
        "\n",
        "* A **loss caiu de 0.0621 → 0.0347**, sinal de que o modelo está **aprendendo e convergindo bem**.\n",
        "* A **acurácia no treino passou de 98,3% para 99,2%** — quase perfeita.\n",
        "* Não há oscilação brusca → indica estabilidade no processo de otimização com Adam.\n",
        "\n",
        "📌 Isso já sugere um bom modelo, mas **o mais importante** é verificar o desempenho **no conjunto de teste**, que vem a seguir.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 2. **Desempenho no conjunto de teste (threshold = 0.5)**\n",
        "\n",
        "```\n",
        "Acurácia : 0.967\n",
        "Precisão : 1.000\n",
        "Recall   : 0.900\n",
        "F1-score : 0.947\n",
        "Matriz de confusão:\n",
        " [[20  0]\n",
        " [ 1  9]]\n",
        "```\n",
        "\n",
        "✅ **Interpretação:**\n",
        "\n",
        "* **Acurácia de 96,7%** → o modelo acerta quase todas as previsões no teste.\n",
        "* **Precisão de 100%** → quando ele prevê que é *Versicolor*, ele **nunca erra**.\n",
        "  → Nenhum **falso positivo**.\n",
        "* **Recall de 90%** → ele identificou 9 de 10 Versicolor reais, ou seja, **só deixou passar 1 caso positivo**.\n",
        "* **F1-score de 0.947** → equilíbrio excelente entre precisão e recall.\n",
        "\n",
        "📊 Matriz de confusão:\n",
        "\n",
        "| Real \\ Predito | 0  | 1 |\n",
        "| -------------- | -- | - |\n",
        "| **0** (neg)    | 20 | 0 |\n",
        "| **1** (pos)    | 1  | 9 |\n",
        "\n",
        "👉 O modelo:\n",
        "\n",
        "* Acertou todos os 20 negativos (classe 0)\n",
        "* Acertou 9 de 10 positivos (classe 1)\n",
        "* Não cometeu falsos positivos (muito bom para classificadores binários)\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 3. **Tuning de limiar (threshold)**\n",
        "\n",
        "```\n",
        "Top 5 thresholds\n",
        "Thr   Acc   Prec    Rec     F1\n",
        "0.35  0.967  1.000  0.900  0.947\n",
        "0.40  0.967  1.000  0.900  0.947\n",
        "0.45  0.967  1.000  0.900  0.947\n",
        "0.50  0.967  1.000  0.900  0.947\n",
        "0.55  0.967  1.000  0.900  0.947\n",
        "```\n",
        "\n",
        "✅ **Interpretação:**\n",
        "\n",
        "* O desempenho não muda muito com o limiar de 0.35 a 0.55 → indica que o **modelo está bem calibrado**.\n",
        "* Isso sugere que as probabilidades previstas têm **boa separação entre classes**.\n",
        "* Como a precisão já é perfeita e o recall alto, **não há ganho real ao ajustar o threshold**.\n",
        "\n",
        "📌 Isso é sinal de **modelo maduro e estável**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 4. Diagnóstico geral\n",
        "\n",
        "| Métrica               | Valor         | Interpretação                                  |\n",
        "| --------------------- | ------------- | ---------------------------------------------- |\n",
        "| Loss final baixa      | 0.0347        | Modelo aprendeu bem a relação input-output     |\n",
        "| Acurácia treino/teste | 0.992 / 0.967 | Pouca diferença — não há overfitting relevante |\n",
        "| Precisão no teste     | 1.000         | Nenhum falso positivo                          |\n",
        "| Recall no teste       | 0.900         | Pouquíssimos falsos negativos                  |\n",
        "| F1-score              | 0.947         | Excelente equilíbrio                           |\n",
        "| Threshold tuning      | Estável       | Modelo bem calibrado, previsões consistentes   |\n",
        "\n",
        "✅ Isso indica um **modelo robusto**, com **generalização muito boa**, e **alto poder preditivo**.\n",
        "\n",
        "---\n",
        "\n",
        "## ⚡ 5. Possíveis (pequenos) ajustes se quisesse ir além\n",
        "\n",
        "Mesmo com desempenho excelente, você poderia:\n",
        "\n",
        "* 📊 **Aumentar recall de 0.90 → 1.00**\n",
        "  → Ajustando levemente o threshold para baixo (ex.: 0.30–0.35) ou fazendo leve oversampling da classe positiva durante o treino.\n",
        "\n",
        "* 🧪 **Fazer validação cruzada (K-Fold)** para garantir que esses resultados não são fruto do acaso no split.\n",
        "\n",
        "* 🧠 **Testar dropout leve** para garantir ainda mais robustez contra overfitting.\n",
        "\n",
        "* 📈 **Avaliar curva ROC e AUC** para confirmar separação ótima de classes.\n",
        "\n",
        "---\n",
        "\n",
        "## 🏁 Conclusão\n",
        "\n",
        "👉 **Sim, você tem um excelente modelo preditivo.**\n",
        "\n",
        "* Ele generaliza bem (sem overfitting),\n",
        "* Tem precisão perfeita, recall alto e F1 robusto,\n",
        "* E responde de forma estável a mudanças de threshold.\n",
        "\n",
        "✅ **Indicadores de modelo preditivo forte:**\n",
        "\n",
        "* Baixa loss final\n",
        "* Alta acurácia no teste\n",
        "* Alta precisão e recall\n",
        "* F1 próximo de 1\n",
        "* Threshold tuning estável\n",
        "\n",
        "🚀 **Resumo em linguagem simples:**\n",
        "\n",
        "> “Seu modelo aprendeu muito bem a diferenciar Versicolor das outras flores. Ele praticamente não erra, está bem calibrado e responde de forma consistente. Para aplicações reais, já está em um patamar excelente.”\n",
        "\n",
        "---\n",
        "\n",
        "Se você quiser, posso **plotar a curva ROC e calcular AUC** para dar uma **visão estatística adicional** da separação entre classes. Quer que eu faça isso? 📈🧠✨\n"
      ],
      "metadata": {
        "id": "vz71o9UiezwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Definição do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 3. Definir modelo: regressão logística\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features → 1 saída (probabilidade de ser Versicolor)\n",
        "\n",
        "# 4. Definir função de perda e algoritmo de otimização\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # Sigmoid + Binary Cross Entropy\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)\n",
        "\n",
        "# 👇 Adicionando prints\n",
        "print(\"Modelo definido:\\n\", modelo)\n",
        "print(\"\\nParâmetros iniciais do modelo:\")\n",
        "for nome, param in modelo.named_parameters():\n",
        "    print(f\"{nome}: {param.data}\")\n",
        "\n",
        "print(\"\\nFunção de perda:\", funcao_perda)\n",
        "print(\"\\nOtimizador:\", optimizer)\n"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — esse é o **estado inicial do seu modelo de regressão logística binária** em PyTorch.\n",
        "Vamos destrinchar cada parte dos resultados para entender **o que eles significam na prática** antes de iniciar o treinamento 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. **Arquitetura do modelo**\n",
        "\n",
        "```\n",
        "Modelo definido:\n",
        " Linear(in_features=4, out_features=1, bias=True)\n",
        "```\n",
        "\n",
        "👉 Isso significa que:\n",
        "\n",
        "* O modelo é uma **camada linear** com:\n",
        "\n",
        "  * `4` entradas (features: comprimento e largura de sépala e pétala no dataset Iris),\n",
        "  * `1` saída (logit — usado depois pela Sigmoid para gerar probabilidade de “Versicolor”).\n",
        "* `bias=True` → o modelo tem um termo de intercepto (b) além dos pesos.\n",
        "\n",
        "📌 **Interpretação prática:**\n",
        "Este modelo é exatamente equivalente a **uma regressão logística clássica**:\n",
        "[\n",
        "\\hat{y} = \\sigma(w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + b)\n",
        "]\n",
        "onde (\\sigma) é a função sigmoide.\n",
        "\n",
        "---\n",
        "\n",
        "## 🪜 2. **Parâmetros iniciais**\n",
        "\n",
        "```\n",
        "weight: tensor([[-0.0660, -0.3629,  0.0117, -0.3415]])\n",
        "bias: tensor([-0.4242])\n",
        "```\n",
        "\n",
        "👉 Estes são os **valores iniciais dos pesos e bias**, atribuídos aleatoriamente por PyTorch.\n",
        "\n",
        "* `weight` → vetor de 4 valores, um para cada feature:\n",
        "\n",
        "  * x₁: -0.0660\n",
        "  * x₂: -0.3629\n",
        "  * x₃:  0.0117\n",
        "  * x₄: -0.3415\n",
        "\n",
        "* `bias` → -0.4242\n",
        "\n",
        "📌 **Interpretação prática:**\n",
        "\n",
        "* No início, o modelo **não aprendeu nada ainda**.\n",
        "* Esses valores não têm nenhum significado estatístico real.\n",
        "* Após algumas iterações de gradiente descendente, esses números vão **se ajustar** para refletir os padrões do dataset Iris.\n",
        "\n",
        "⚠️ Importante:\n",
        "Mesmo valores pequenos **podem gerar probabilidades enviesadas no início**, especialmente com bias negativo — mas isso é normal.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧮 3. **Função de perda**\n",
        "\n",
        "```\n",
        "Função de perda: BCEWithLogitsLoss()\n",
        "```\n",
        "\n",
        "👉 Essa loss combina duas coisas:\n",
        "\n",
        "1. A transformação **Sigmoid** dos logits → converte a saída linear (ex. 0.87) para probabilidade (ex. 0.70),\n",
        "2. O cálculo da **Binary Cross Entropy**, que mede quão distante essa probabilidade está do rótulo real (0 ou 1).\n",
        "\n",
        "[\n",
        "\\text{Loss} = -[y \\cdot \\log(\\sigma(z)) + (1 - y) \\cdot \\log(1 - \\sigma(z))]\n",
        "]\n",
        "\n",
        "✅ Vantagem: usar `BCEWithLogitsLoss` é **mais numericamente estável** que usar `Sigmoid` + `BCELoss` separadamente.\n",
        "\n",
        "---\n",
        "\n",
        "## ⚡ 4. **Otimizador**\n",
        "\n",
        "```\n",
        "Otimizador: SGD (\n",
        "    lr: 0.1\n",
        "    momentum: 0\n",
        "    weight_decay: 0\n",
        ")\n",
        "```\n",
        "\n",
        "👉 Esse é o **otimizador de gradiente descendente estocástico** (Stochastic Gradient Descent):\n",
        "\n",
        "* **`lr=0.1`** → taxa de aprendizado relativamente alta (o modelo vai atualizar parâmetros com passos largos).\n",
        "* **`momentum=0`** → sem suavização extra no caminho de descida (treino mais “direto”).\n",
        "* **`weight_decay=0`** → sem regularização L2 no momento.\n",
        "\n",
        "📌 **Interpretação prática:**\n",
        "\n",
        "* Isso é suficiente para modelos pequenos como regressão logística.\n",
        "* Mas se o treino oscilar muito ou não convergir, **ajustar `lr` ou adicionar momentum** ajuda.\n",
        "* Em problemas maiores, usar Adam costuma ser mais eficiente.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 5. **Diagnóstico do estado inicial**\n",
        "\n",
        "| Elemento                | Valor atual                   | Interpretação                               |\n",
        "| ----------------------- | ----------------------------- | ------------------------------------------- |\n",
        "| Arquitetura             | Linear(4→1)                   | Modelo de regressão logística binária       |\n",
        "| Pesos e bias            | valores pequenos e aleatórios | Ponto de partida neutro para aprendizado    |\n",
        "| Função de perda         | BCEWithLogitsLoss             | Ideal para classificação binária            |\n",
        "| Otimizador              | SGD, lr=0.1                   | Simples, eficiente p/ modelo pequeno        |\n",
        "| Momento / regularização | momentum=0, weight_decay=0    | Treino “cru” — suficiente para caso simples |\n",
        "\n",
        "✅ Isso está **exatamente como deveria estar antes de iniciar o treinamento**.\n",
        "\n",
        "---\n",
        "\n",
        "## 📝 Em resumo:\n",
        "\n",
        "* O modelo ainda **não tem nenhum conhecimento** — está pronto para aprender.\n",
        "* Os pesos e bias iniciais foram sorteados e serão ajustados pelo treinamento.\n",
        "* A função de perda e o otimizador estão bem configurados para um problema binário pequeno (como o Iris).\n",
        "* Você está na etapa **“pré-treino”**, e o próximo passo natural é:\n",
        "\n",
        "  1. Rodar um loop de treinamento com `loss.backward()` e `optimizer.step()`,\n",
        "  2. Monitorar a perda decaindo com as épocas,\n",
        "  3. Ver a precisão aumentar no treino e no teste.\n",
        "\n",
        "👉 Em linguagem simples:\n",
        "\n",
        "> “O modelo foi criado e está zerado. Agora vem a parte de ensinar ele a reconhecer a flor Versicolor.” 🌸🧠\n",
        "\n",
        "---\n",
        "\n",
        "Se você quiser, posso escrever o **loop de treinamento completo** usando esse modelo e mostrar como os pesos evoluem ao longo das épocas 📈.\n",
        "Quer que eu faça isso? 🚀\n"
      ],
      "metadata": {
        "id": "AwwUpF5sg50Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# 0) Dados (Iris → binário: Versicolor=1, caso contrário=0)\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)\n",
        "\n",
        "# Split estratificado (80/20) e padronização (boa prática p/ regressão logística)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True\n",
        ")\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 1) Modelo: regressão logística (Linear 4→1; Sigmoid embutida na loss)\n",
        "modelo = nn.Linear(4, 1)\n",
        "\n",
        "# 2) Função de perda e otimizador\n",
        "funcao_perda = nn.BCEWithLogitsLoss()       # estável numericamente (logits + BCE)\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)  # simples e funciona bem aqui\n",
        "\n",
        "# 3) Loop de treinamento\n",
        "EPOCHS = 500\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    # --- modo treino ---\n",
        "    modelo.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward\n",
        "    logits = modelo(X_train_t)              # saída linear\n",
        "    loss = funcao_perda(logits, y_train_t)  # BCE + Sigmoid (interno)\n",
        "\n",
        "    # backward\n",
        "    loss.backward()\n",
        "\n",
        "    # atualização dos pesos\n",
        "    optimizer.step()\n",
        "\n",
        "    # logging a cada 50 épocas\n",
        "    if epoch % 50 == 0 or epoch == 1:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(modelo(X_train_t))\n",
        "            preds_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (preds_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch:3d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 4) Avaliação no TESTE\n",
        "modelo.eval()\n",
        "with torch.no_grad():\n",
        "    probs_te = torch.sigmoid(modelo(X_test_t))\n",
        "    preds_te = (probs_te >= 0.5).float()\n",
        "\n",
        "# métricas no teste\n",
        "y_true = y_test_t.numpy().ravel()\n",
        "y_pred = preds_te.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true, y_pred)\n",
        "prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "\n",
        "print(\"\\n=== Métricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acurácia : {acc:.3f}\")\n",
        "print(f\"Precisão : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n"
      ],
      "metadata": {
        "id": "ynpcgUWAhdbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — o resultado que você obteve mostra um **modelo de regressão logística que aprendeu alguma coisa**, mas ainda **não tem um desempenho preditivo muito bom**.\n",
        "Vamos analisar cada parte do output com calma 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. **Evolução do treinamento**\n",
        "\n",
        "```\n",
        "[  1/500] loss=0.6510  acc_train@0.5=0.575\n",
        "[ 50/500] loss=0.5371  acc_train@0.5=0.742\n",
        "[100/500] loss=0.5136  acc_train@0.5=0.725\n",
        "...\n",
        "[500/500] loss=0.4904  acc_train@0.5=0.742\n",
        "```\n",
        "\n",
        "✅ **O que isso significa:**\n",
        "\n",
        "* A perda (loss) caiu de **0.6510 → 0.4904**, o que mostra que o modelo **está aprendendo**.\n",
        "* A acurácia de treino subiu de **57,5% → 74,2%**, estabilizando a partir da época ~200.\n",
        "\n",
        "⚠️ **Mas observe:**\n",
        "\n",
        "* A loss **parou de cair significativamente** após ~250 épocas.\n",
        "* A acurácia também **estagnou em ~74%**.\n",
        "  → Isso sugere que **o modelo atingiu um platô**, ou seja, aprendeu o que conseguia com sua capacidade atual (apenas uma camada linear).\n",
        "\n",
        "📌 Interpretação:\n",
        "\n",
        "> O modelo captou alguns padrões, mas não conseguiu capturar toda a complexidade dos dados.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 2. **Desempenho no conjunto de teste**\n",
        "\n",
        "```\n",
        "Acurácia : 0.633\n",
        "Precisão : 0.429\n",
        "Recall   : 0.300\n",
        "F1-score : 0.353\n",
        "```\n",
        "\n",
        "👉 Esses números contam a verdade sobre a capacidade preditiva:\n",
        "\n",
        "| Métrica  | Valor | Interpretação                                                                   |\n",
        "| -------- | ----- | ------------------------------------------------------------------------------- |\n",
        "| Acurácia | 0.633 | Só 63,3% de acertos no conjunto de teste.                                       |\n",
        "| Precisão | 0.429 | Quando prevê “Versicolor”, só acerta em 43% dos casos. Muitos falsos positivos. |\n",
        "| Recall   | 0.300 | Só acerta 30% dos positivos reais. Muitos falsos negativos.                     |\n",
        "| F1-score | 0.353 | Baixo equilíbrio entre precisão e recall.                                       |\n",
        "\n",
        "📌 **Resumo**:\n",
        "\n",
        "* O modelo erra bastante em ambas as classes.\n",
        "* Tem **baixa precisão e recall**, então **não identifica bem a classe positiva (Versicolor)**.\n",
        "* Acurácia global baixa indica que **não compensa bem nem prevendo tudo como 0**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 3. Diagnóstico\n",
        "\n",
        "| Sintoma                              | Causa provável                                                          |\n",
        "| ------------------------------------ | ----------------------------------------------------------------------- |\n",
        "| Platô de loss e acurácia             | Limitação do modelo linear (pouca capacidade para padrões não lineares) |\n",
        "| Precisão e recall baixos             | O modelo não separa bem as classes                                      |\n",
        "| Gap entre treino (74%) e teste (63%) | Possível overfitting leve ou má generalização                           |\n",
        "| Treinamento estabilizado cedo        | Talvez LR alta demais, sem refinamento fino                             |\n",
        "\n",
        "👉 Em resumo:\n",
        "\n",
        "> O modelo **aprendeu algo**, mas não tem poder preditivo forte.\n",
        "> Isso é típico de modelos lineares simples em problemas com **fronteiras de decisão mais complexas**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧰 4. Como melhorar significativamente\n",
        "\n",
        "### 🔸 **1. Normalizar/Padronizar os dados**\n",
        "\n",
        "Você já pode estar fazendo isso — mas se não, é essencial para regressão logística.\n",
        "\n",
        "### 🔸 **2. Aumentar capacidade do modelo**\n",
        "\n",
        "Adicionar uma camada escondida simples:\n",
        "\n",
        "```python\n",
        "modelo = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)\n",
        ")\n",
        "```\n",
        "\n",
        "➡️ Isso permite aprender **padrões não lineares**, melhorando recall e precisão.\n",
        "\n",
        "### 🔸 **3. Otimizador mais eficiente**\n",
        "\n",
        "Trocar de `SGD` para `Adam`:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.01)\n",
        "```\n",
        "\n",
        "➡️ Adam converge mais rápido e costuma escapar melhor de platôs.\n",
        "\n",
        "### 🔸 **4. Ajustar learning rate**\n",
        "\n",
        "`lr=0.1` é alto para alguns problemas. Tente `0.01` ou `0.005` para treinos mais suaves.\n",
        "\n",
        "### 🔸 **5. Regularização leve**\n",
        "\n",
        "Adicionar `weight_decay` no otimizador pode evitar overfitting e melhorar generalização:\n",
        "\n",
        "```python\n",
        "optimizer = torch.optim.Adam(modelo.parameters(), lr=0.01, weight_decay=1e-4)\n",
        "```\n",
        "\n",
        "### 🔸 **6. Tuning de threshold**\n",
        "\n",
        "Ajustar o limiar de decisão pode **melhorar precisão ou recall**, mas isso **não resolve** falta de aprendizado.\n",
        "→ Primeiro melhore o modelo.\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 5. Comparando com um bom modelo (referência)\n",
        "\n",
        "| Métrica         | Atual modelo | Modelo bom (esperado) |\n",
        "| --------------- | ------------ | --------------------- |\n",
        "| Loss final      | 0.49         | 0.05 – 0.2            |\n",
        "| Acurácia treino | 0.742        | 0.90+                 |\n",
        "| Acurácia teste  | 0.633        | 0.85–0.97             |\n",
        "| Precisão        | 0.429        | 0.90+                 |\n",
        "| Recall          | 0.300        | 0.85+                 |\n",
        "| F1              | 0.353        | 0.90+                 |\n",
        "\n",
        "📌 Esse tipo de diferença mostra claramente que o modelo atual ainda é **fraco** e precisa ser aprimorado.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Conclusão\n",
        "\n",
        "❌ **Não é um bom modelo preditivo** no estado atual.\n",
        "✅ **Mas é um modelo que aprendeu alguma coisa**, e com pequenos ajustes — especialmente na arquitetura e otimização — ele pode se tornar bom.\n",
        "\n",
        "**Problema:** modelo linear limitado.\n",
        "**Solução:** aumentar capacidade, melhorar otimização e calibrar.\n",
        "\n",
        "> 🧠 “Você está com um motor 1.0 tentando correr uma corrida de F1 — é hora de turbinar um pouco.”\n",
        "\n",
        "---\n",
        "\n",
        "Se você quiser, posso adaptar seu código atual com:\n",
        "\n",
        "* uma camada escondida simples,\n",
        "* Adam,\n",
        "* LR menor,\n",
        "* e mostrar a comparação de métricas antes e depois.\n",
        "\n",
        "Quer que eu monte essa versão melhorada agora? 🚀✨\n"
      ],
      "metadata": {
        "id": "Yfc6ujtWiLoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Iris binário (Versicolor=1) — MLP + Adam + padronização + threshold tuning\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split estratificado + padronização (fit no treino, transform no teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, stratify=y, shuffle=True\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 3) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo — MLP simples (mais capacidade que regressão logística)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)   # logits\n",
        ")\n",
        "\n",
        "# 5) Loss e Otimizador (Adam + L2)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 6) Treino\n",
        "EPOCHS = 800\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0 or epoch == 1:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            preds_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (preds_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch:3d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 7) Avaliação no teste (threshold=0.5)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "y_pred05 = (test_probs >= 0.5).astype(float)\n",
        "\n",
        "def metrics(y_true, y_pred):\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "acc05, prec05, rec05, f105, cm05 = metrics(y_true, y_pred05)\n",
        "try:\n",
        "    auc = roc_auc_score(y_true, test_probs)\n",
        "except Exception:\n",
        "    auc = None\n",
        "\n",
        "print(\"\\n=== TESTE @ threshold=0.5 ===\")\n",
        "print(f\"Acurácia : {acc05:.3f}\")\n",
        "print(f\"Precisão : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", cm05)\n",
        "if auc is not None:\n",
        "    print(f\"AUC-ROC  : {auc:.3f}\")\n",
        "\n",
        "# 8) Varredura de limiar (max F1)\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc, prec, rec, f1, cm = metrics(y_true, y_pred_t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(\"\\n=== Varredura de limiar — top 5 por F1 (TESTE) ===\")\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acurácia  : {best['acc']:.3f}\")\n",
        "print(f\"Precisão  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confusão:\\n\", best['cm'])\n",
        "if auc is not None:\n",
        "    print(f\"AUC-ROC  : {auc:.3f}  (não depende do threshold)\")\n"
      ],
      "metadata": {
        "id": "0AL11Fh_iOR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente 👌 — esse resultado é **muito diferente** do seu modelo linear anterior e mostra que agora você realmente tem um **modelo preditivo de alta performance**.\n",
        "Vamos analisar por etapas para entender o que aconteceu e **por que esse modelo é bom** 👇\n",
        "\n",
        "---\n",
        "\n",
        "## 🧠 1. Evolução do treinamento\n",
        "\n",
        "```\n",
        "[  1/800] loss=0.7672  acc_train@0.5=0.483\n",
        "[100/800] loss=0.0837  acc_train@0.5=0.975\n",
        "[200/800] loss=0.0461  acc_train@0.5=0.983\n",
        "...\n",
        "[800/800] loss=0.0298  acc_train@0.5=0.983\n",
        "```\n",
        "\n",
        "✅ **Interpretação:**\n",
        "\n",
        "* A perda caiu de **0.767 → 0.0298**, ou seja, uma **redução muito grande e consistente** — o modelo aprendeu a mapear bem os padrões do dataset.\n",
        "* A acurácia de treino subiu de **48,3% para 98,3%**, estabilizando cedo (por volta da época 200).\n",
        "* A curva de loss é suave, sem oscilações → **boa convergência com Adam**.\n",
        "* O modelo **não está overfittando de forma preocupante**, porque o desempenho no teste também é alto (ver abaixo).\n",
        "\n",
        "📌 **Conclusão:**\n",
        "O modelo conseguiu **aprender a estrutura do problema** e manteve estabilidade durante o treino — isso é um forte indicador de um bom treinamento.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 2. Desempenho no conjunto de teste (threshold = 0.5)\n",
        "\n",
        "```\n",
        "Acurácia : 0.967\n",
        "Precisão : 1.000\n",
        "Recall   : 0.900\n",
        "F1-score : 0.947\n",
        "Matriz de confusão:\n",
        " [[20  0]\n",
        " [ 1  9]]\n",
        "AUC-ROC  : 0.995\n",
        "```\n",
        "\n",
        "| Métrica  | Valor | Interpretação                                                                 |\n",
        "| -------- | ----- | ----------------------------------------------------------------------------- |\n",
        "| Acurácia | 0.967 | 96,7% de acertos — excelente para uma tarefa de classificação binária pequena |\n",
        "| Precisão | 1.000 | Nenhum falso positivo — modelo super confiável para positivos                 |\n",
        "| Recall   | 0.900 | Acerta 90% dos casos positivos (falhou em apenas 1)                           |\n",
        "| F1-score | 0.947 | Equilíbrio excelente entre precisão e recall                                  |\n",
        "| AUC-ROC  | 0.995 | Separação quase perfeita entre classes                                        |\n",
        "\n",
        "📊 **Matriz de confusão**:\n",
        "\n",
        "| Real \\ Predito | 0  | 1 |\n",
        "| -------------- | -- | - |\n",
        "| 0 (negativo)   | 20 | 0 |\n",
        "| 1 (positivo)   | 1  | 9 |\n",
        "\n",
        "👉 Isso mostra:\n",
        "\n",
        "* **20 acertos em 20 negativos**\n",
        "* **9 acertos em 10 positivos**\n",
        "* **0 falsos positivos**\n",
        "* Apenas **1 falso negativo**\n",
        "\n",
        "📌 **Conclusão:**\n",
        "Esse é **um modelo altamente discriminativo**, com excelente equilíbrio entre sensibilidade e precisão — praticamente perfeito para este problema.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧭 3. Varredura de threshold\n",
        "\n",
        "```\n",
        "Top 5 por F1 (threshold 0.15–0.35): F1 = 0.947\n",
        "```\n",
        "\n",
        "👉 O F1 ficou **idêntico** para todos esses limiares.\n",
        "➡️ Isso indica que:\n",
        "\n",
        "* As probabilidades previstas estão **muito bem separadas entre classes** (não há valores ambíguos próximos de 0.5).\n",
        "* O modelo está **bem calibrado** — ele não depende fortemente de um threshold “mágico” para ter bom desempenho.\n",
        "* A estabilidade do F1 em vários thresholds reforça que a **confiança do modelo nas predições é alta**.\n",
        "\n",
        "📌 **Conclusão:**\n",
        "Modelo bem calibrado + margens de decisão largas = ótimo comportamento preditivo.\n",
        "\n",
        "---\n",
        "\n",
        "## 📊 4. Comparação com o modelo anterior (linear)\n",
        "\n",
        "| Métrica         | Modelo Linear | Modelo MLP (atual) |\n",
        "| --------------- | ------------- | ------------------ |\n",
        "| Loss final      | 0.49          | **0.0298** ✅       |\n",
        "| Acurácia treino | 0.742         | **0.983** ✅        |\n",
        "| Acurácia teste  | 0.633         | **0.967** ✅        |\n",
        "| Precisão        | 0.429         | **1.000** ✅        |\n",
        "| Recall          | 0.300         | **0.900** ✅        |\n",
        "| F1              | 0.353         | **0.947** ✅        |\n",
        "| AUC-ROC         | —             | **0.995** ✅        |\n",
        "\n",
        "📌 Agora seu modelo:\n",
        "\n",
        "* **Generaliza muito melhor**,\n",
        "* **Aprende padrões não lineares** graças à camada escondida,\n",
        "* **Classifica com alta confiança** (precisão perfeita),\n",
        "* E tem recall alto, ou seja, **identifica quase todos os casos positivos**.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧰 5. Diagnóstico final\n",
        "\n",
        "| Ponto forte               | Evidência                                           |\n",
        "| ------------------------- | --------------------------------------------------- |\n",
        "| Aprendizado efetivo       | Queda forte e estável na loss                       |\n",
        "| Alta capacidade preditiva | Acurácia 96,7%, F1 0,947, AUC 0,995                 |\n",
        "| Baixo overfitting         | Acurácia treino e teste próximas                    |\n",
        "| Alta calibragem           | F1 estável para diferentes thresholds               |\n",
        "| Modelo leve               | Apenas uma hidden layer — baixo custo computacional |\n",
        "\n",
        "⚠️ **Possível ajuste** (se fosse um caso real):\n",
        "\n",
        "* Aumentar um pouco o recall (de 0.90 para 1.0) ajustando o threshold para **abaixo de 0.5** (ex.: 0.15 já está ótimo).\n",
        "* Avaliar com validação cruzada se o dataset for pequeno — só para garantir robustez.\n",
        "\n",
        "---\n",
        "\n",
        "## ✅ Conclusão Final\n",
        "\n",
        "📌 **Sim, agora você tem um excelente modelo preditivo.**\n",
        "\n",
        "* **Aprendeu bem**, sem overfitting,\n",
        "* **Alta precisão e recall**,\n",
        "* **Alta AUC** indica separação clara das classes,\n",
        "* E **boa estabilidade com diferentes thresholds**.\n",
        "\n",
        "👉 Em linguagem simples:\n",
        "\n",
        "> 🧠 “Antes seu modelo chutava bem. Agora ele está acertando de verdade.” ⚡🌸\n",
        "\n",
        "---\n",
        "\n",
        "Se você quiser, posso montar um gráfico com:\n",
        "\n",
        "* **Curva ROC + AUC**,\n",
        "* **Distribuição das probabilidades por classe**,\n",
        "* **Curva Precision–Recall**,\n",
        "\n",
        "para **visualizar graficamente a qualidade desse classificador**. Quer que eu gere esses gráficos? 📈✨\n"
      ],
      "metadata": {
        "id": "-vVtGdh3jd7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execução do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treino\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad() # reseta gradiente senão acumula\n",
        "    outputs = modelo(X)\n",
        "    loss = funcao_perda(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Época [{epoch+1}/100], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}