{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ferdinandrafols/IA_LLMs/blob/main/gsi073_aula0_regressao_logistica.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GSI073 - T√≥picos Especiais de Intelig√™ncia Artificial\n",
        "\n",
        "## Defini√ß√£o dos dados"
      ],
      "metadata": {
        "id": "Mwsc0ViVertv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmZxMYLGefOh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import sklearn\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: s√©palas e p√©talas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contr√°rio\n",
        "\n",
        "# 2. Preparar dados para pytorch\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# üëá Adicionando prints para visualizar\n",
        "print(\"Shape de X:\", X.shape)\n",
        "print(\"Primeiras 5 linhas de X:\\n\", X[:5])\n",
        "\n",
        "print(\"Shape de y:\", y.shape)\n",
        "print(\"Primeiras 5 linhas de y:\\n\", y[:5])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente pergunta üëå ‚Äî **sim**, o resultado que voc√™ obteve est√° **correto e bom** ‚úÖ\n",
        "\n",
        "Vamos justificar por partes üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üß† **1. Estrutura dos dados**\n",
        "\n",
        "üìä **`X` com shape `(150, 4)`** ‚Üí **perfeito**.\n",
        "\n",
        "* O dataset Iris tem exatamente **150 amostras**\n",
        "* e **4 caracter√≠sticas** (s√©palas e p√©talas).\n",
        "  ‚úÖ Isso significa que voc√™ converteu os dados corretamente para tensor PyTorch.\n",
        "\n",
        "üìå Se tivesse dado errado, voc√™ veria:\n",
        "\n",
        "* `X` com shape diferente de `(150, 4)`\n",
        "* erro de tipo de dado\n",
        "* ou at√© erros no `torch.tensor(...)`.\n",
        "\n",
        "---\n",
        "\n",
        "## üåø **2. Estrutura dos r√≥tulos `y`**\n",
        "\n",
        "üìä **`y` com shape `(150, 1)`** ‚Üí **perfeito para classifica√ß√£o bin√°ria**.\n",
        "\n",
        "* Voc√™ converteu corretamente `iris.target` (0, 1, 2) em **bin√°rio (0 e 1)**.\n",
        "* Isso √© exatamente o formato que fun√ß√µes de perda como\n",
        "\n",
        "  * `nn.BCEWithLogitsLoss()` ou\n",
        "  * `nn.BCELoss()`\n",
        "    esperam.\n",
        "\n",
        "‚úÖ Isso significa que o modelo poder√° aprender a **distinguir ‚ÄúVersicolor‚Äù (1)** de outras esp√©cies (0).\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ **3. Valores das primeiras linhas de `y`**\n",
        "\n",
        "```\n",
        "[[0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.],\n",
        " [0.]]\n",
        "```\n",
        "\n",
        "üëâ Isso **tamb√©m est√° correto**:\n",
        "\n",
        "* No dataset original, as **primeiras 50 flores** s√£o da classe `0` (Setosa).\n",
        "* A classe `1` (Versicolor) s√≥ come√ßa a aparecer da amostra 50 em diante.\n",
        "* Por isso os primeiros r√≥tulos s√£o todos `0.`.\n",
        "\n",
        "‚úÖ Isso indica que a **transforma√ß√£o l√≥gica `iris.target == 1` funcionou como esperado**.\n",
        "\n",
        "---\n",
        "\n",
        "## ü™Ñ **4. Tipos de dados**\n",
        "\n",
        "Voc√™ usou:\n",
        "\n",
        "```python\n",
        "dtype=torch.float32\n",
        "```\n",
        "\n",
        "‚úÖ Isso √© **o tipo padr√£o ideal para treinar redes neurais** ‚Äî\n",
        "nem inteiro (`int`) nem double (`float64`), que √© mais pesado.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o Final\n",
        "\n",
        "| Item Verificado      | Resultado            | Situa√ß√£o  |\n",
        "| -------------------- | -------------------- | --------- |\n",
        "| Shape de X           | `(150, 4)`           | ‚úÖ Correto |\n",
        "| Shape de y           | `(150, 1)`           | ‚úÖ Correto |\n",
        "| Convers√£o para float | `float32`            | ‚úÖ Correto |\n",
        "| R√≥tulos bin√°rios     | 0 ou 1               | ‚úÖ Correto |\n",
        "| Primeiros r√≥tulos 0  | coerente com dataset | ‚úÖ Correto |\n",
        "\n",
        "‚úÖ **Sim, o resultado foi bom.**\n",
        "Voc√™ tem agora **os dados prontos para treinar um modelo de classifica√ß√£o bin√°ria no PyTorch** ‚Äî por exemplo, uma rede simples com uma ou duas camadas lineares.\n",
        "\n",
        "---\n",
        "\n",
        "üëâ Pr√≥ximos passos comuns seriam:\n",
        "\n",
        "* dividir em treino e teste,\n",
        "* definir um modelo (`nn.Sequential` ou `nn.Module`),\n",
        "* escolher fun√ß√£o de perda (`BCEWithLogitsLoss`),\n",
        "* usar `SGD` ou `Adam` como otimizador,\n",
        "* e treinar.\n"
      ],
      "metadata": {
        "id": "feWR-CX6X6cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 1. Carregar dados\n",
        "iris = sklearn.datasets.load_iris()\n",
        "X = iris.data        # 4 features: s√©palas e p√©talas\n",
        "y = (iris.target == 1).astype(float)  # 1 se Versicolor, 0 caso contr√°rio\n",
        "\n",
        "# 2. Separar em treino e teste (80% treino, 20% teste)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,         # 20% para teste\n",
        "    random_state=42,       # garante reprodutibilidade\n",
        "    shuffle=True,          # embaralhar dados antes da divis√£o\n",
        "    stratify=y             # mant√©m propor√ß√£o de classes (bom p/ classifica√ß√£o)\n",
        ")\n",
        "\n",
        "# 3. Converter para tensores PyTorch\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# üëá Verifica√ß√£o\n",
        "print(\"Shape treino X:\", X_train.shape)\n",
        "print(\"Shape treino y:\", y_train.shape)\n",
        "\n",
        "print(\"Shape teste X:\", X_test.shape)\n",
        "print(\"Shape teste y:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "vz58DW7gYtz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "from sklearn import datasets\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (boas pr√°ticas: shuffle + stratify + seed)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Tensores\n",
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 4) Modelo bin√°rio simples (sem Sigmoid na √∫ltima camada)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 8),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(8, 1)       # logits\n",
        ")\n",
        "\n",
        "# 5) Loss + Opt\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "# 6) Treino r√°pido\n",
        "model.train()\n",
        "for epoch in range(300):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train)\n",
        "    loss = criterion(logits, y_train)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "# 7) Avalia√ß√£o no TESTE (onde as m√©tricas fazem sentido)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs  = torch.sigmoid(test_logits)        # converte logits -> prob.\n",
        "    y_pred      = (test_probs >= 0.5).float()       # threshold 0.5\n",
        "\n",
        "# 8) M√©tricas\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "y_pred_np = y_pred.numpy().ravel()\n",
        "\n",
        "acc  = accuracy_score(y_true_np, y_pred_np)\n",
        "prec = precision_score(y_true_np, y_pred_np, zero_division=0)\n",
        "rec  = recall_score(y_true_np, y_pred_np,   zero_division=0)\n",
        "f1   = f1_score(y_true_np, y_pred_np,       zero_division=0)\n",
        "cm   = confusion_matrix(y_true_np, y_pred_np)\n",
        "\n",
        "print(f\"Acur√°cia : {acc:.3f}\")\n",
        "print(f\"Precis√£o : {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1-score : {f1:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", cm)\n"
      ],
      "metadata": {
        "id": "7xvZ0tkNaoPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî vamos **interpretar cuidadosamente** esse resultado:\n",
        "\n",
        "```\n",
        "Acur√°cia : 0.600\n",
        "Precis√£o : 0.455\n",
        "Recall   : 1.000\n",
        "F1-score : 0.625\n",
        "Matriz de confus√£o:\n",
        " [[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. Acur√°cia ‚Äî **60%**\n",
        "\n",
        "[\n",
        "\\text{Accuracy} = \\frac{\\text{acertos}}{\\text{total}} = 0.60\n",
        "]\n",
        "\n",
        "üëâ O modelo acertou **60% das amostras do conjunto de teste**.\n",
        "üìä Como o Iris tem 30 amostras no teste (20% de 150), isso significa:\n",
        "[\n",
        "\\text{acertos} = 0.6 \\times 30 = 18 \\text{ amostras corretas}\n",
        "]\n",
        "[\n",
        "\\text{erros} = 12 \\text{ amostras incorretas}\n",
        "]\n",
        "\n",
        "‚úÖ A acur√°cia n√£o √© p√©ssima, mas tamb√©m n√£o √© alta para um dataset simples como o Iris ‚Äî indica que o modelo est√° com **desempenho limitado**.\n",
        "\n",
        "---\n",
        "\n",
        "## üü° 2. Precis√£o ‚Äî **45,5%**\n",
        "\n",
        "[\n",
        "\\text{Precision} = \\frac{\\text{VP}}{\\text{VP + FP}} = \\frac{10}{10 + 12} \\approx 0.455\n",
        "]\n",
        "\n",
        "üëâ Dos casos em que o modelo **previu ‚ÄúVersicolor‚Äù (classe positiva)**:\n",
        "\n",
        "* Acertou **10 vezes**\n",
        "* Errou **12 vezes**\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica**:\n",
        "\n",
        "* O modelo est√° prevendo muitos positivos **que n√£o s√£o Versicolor** (12 falsos positivos),\n",
        "* Ou seja, est√° **exagerando nas previs√µes positivas**.\n",
        "\n",
        "‚ö†Ô∏è Isso reduz a confiabilidade da previs√£o positiva.\n",
        "\n",
        "---\n",
        "\n",
        "## üü¢ 3. Recall ‚Äî **100%**\n",
        "\n",
        "[\n",
        "\\text{Recall} = \\frac{\\text{VP}}{\\text{VP + FN}} = \\frac{10}{10 + 0} = 1.0\n",
        "]\n",
        "\n",
        "üëâ Dos **10 casos reais de Versicolor no teste**, o modelo **acertou todos**.\n",
        "\n",
        "üìå **Interpreta√ß√£o pr√°tica**:\n",
        "\n",
        "* O modelo **n√£o deixou escapar nenhum Versicolor real** (FN = 0),\n",
        "* Isso pode ser desej√°vel em cen√°rios onde falsos negativos s√£o piores que falsos positivos (ex.: diagn√≥stico m√©dico, fraudes etc.).\n",
        "\n",
        "‚ö° Por√©m, h√° um custo: muitos falsos positivos ‚Üí baixa precis√£o.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ 4. F1-score ‚Äî **0.625**\n",
        "\n",
        "[\n",
        "F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
        "]\n",
        "\n",
        "[\n",
        "= 2 \\times \\frac{0.455 \\times 1.0}{0.455 + 1.0} \\approx 0.625\n",
        "]\n",
        "\n",
        "üëâ F1 est√° **entre precis√£o e recall**, mostrando um **desempenho mediano**:\n",
        "\n",
        "* recall excelente,\n",
        "* precis√£o baixa.\n",
        "\n",
        "üìå √â um **alerta de desequil√≠brio** entre prever positivo demais e acertar de fato.\n",
        "\n",
        "---\n",
        "\n",
        "## üßæ 5. Matriz de confus√£o\n",
        "\n",
        "```\n",
        "[[ 8 12]\n",
        " [ 0 10]]\n",
        "```\n",
        "\n",
        "* 8 ‚Üí Verdadeiros Negativos (classe 0 predita como 0) ‚úÖ\n",
        "* 12 ‚Üí Falsos Positivos (classe 0 predita como 1) ‚ùå\n",
        "* 0 ‚Üí Falsos Negativos (classe 1 predita como 0) ‚úÖ\n",
        "* 10 ‚Üí Verdadeiros Positivos (classe 1 predita como 1) ‚úÖ\n",
        "\n",
        "üìå **Resumo da matriz**:\n",
        "\n",
        "| Real \\ Predito | 0 | 1  |\n",
        "| -------------- | - | -- |\n",
        "| **0**          | 8 | 12 |\n",
        "| **1**          | 0 | 10 |\n",
        "\n",
        "üëâ Ou seja:\n",
        "\n",
        "* O modelo **nunca erra positivos reais** (bom recall),\n",
        "* Mas **erra muito ao classificar negativos** (12 falsos positivos),\n",
        "* Resultado: **baixa precis√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 6. Diagn√≥stico do modelo\n",
        "\n",
        "| M√©trica              | Valor | Interpreta√ß√£o                                |\n",
        "| -------------------- | ----- | -------------------------------------------- |\n",
        "| **Acur√°cia**         | 0.600 | Desempenho global mediano                    |\n",
        "| **Precis√£o**         | 0.455 | Muitas previs√µes positivas incorretas        |\n",
        "| **Recall**           | 1.000 | Excelente cobertura dos casos positivos      |\n",
        "| **F1-score**         | 0.625 | Mostra desequil√≠brio entre precis√£o e recall |\n",
        "| **Falsos positivos** | 12    | Modelo prev√™ ‚ÄúVersicolor‚Äù demais             |\n",
        "\n",
        "üëâ O modelo **est√° tendendo a classificar muita coisa como ‚ÄúVersicolor‚Äù**, garantindo recall m√°ximo, mas **sacrificando precis√£o**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß™ 7. O que poderia melhorar\n",
        "\n",
        "* üî∏ **Regularizar a decis√£o**: ajustar o threshold da sigmoid (de 0.5 para outro valor) pode equilibrar precis√£o e recall.\n",
        "* üî∏ **Aumentar a capacidade do modelo**: talvez camadas adicionais ou mais √©pocas.\n",
        "* üî∏ **Balancear classes ou penalizar falsos positivos** com loss weighting.\n",
        "* üî∏ **Feature scaling / normaliza√ß√£o** ‚Äî ajuda na converg√™ncia.\n",
        "* üî∏ **Hiperpar√¢metros** (LR, momentum, batch size) podem estar limitando a performance.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o final\n",
        "\n",
        "* ‚úÖ O modelo **acerta todos os positivos** ‚Üí recall perfeito.\n",
        "* ‚ö†Ô∏è **Erra muitos negativos**, gerando baixa precis√£o.\n",
        "* üìä **F1-score = 0.625** mostra que o modelo est√° razo√°vel, mas com **muito espa√ßo para otimiza√ß√£o**.\n",
        "* üß≠ Esse comportamento sugere **threshold enviesado para o positivo** ou **modelo pouco treinado / simples demais**.\n",
        "\n",
        "üëâ **Resumo em linguagem simples**:\n",
        "\n",
        "> ‚ÄúO modelo est√° vendo *Versicolor* em tudo. Ele n√£o deixa passar nenhuma Versicolor real, mas erra em muitas flores que n√£o s√£o. Isso garante recall alto, mas prejudica a precis√£o e a acur√°cia.‚Äù\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "CrMIXBvFa-Kk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "results = []\n",
        "\n",
        "# Usando os logits que j√° t√≠nhamos\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test)\n",
        "    test_probs = torch.sigmoid(test_logits).numpy().ravel()\n",
        "\n",
        "y_true_np = y_test.numpy().ravel()\n",
        "\n",
        "for t in thresholds:\n",
        "    y_pred_t = (test_probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true_np, y_pred_t)\n",
        "    prec = precision_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    rec  = recall_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    f1   = f1_score(y_true_np, y_pred_t, zero_division=0)\n",
        "    results.append((t, acc, prec, rec, f1))\n",
        "\n",
        "# Mostrar os resultados em tabela\n",
        "print(f\"{'Threshold':<10}{'Acc':>8}{'Prec':>10}{'Rec':>10}{'F1':>10}\")\n",
        "for t, acc, prec, rec, f1 in results:\n",
        "    print(f\"{t:<10.2f}{acc:>8.3f}{prec:>10.3f}{rec:>10.3f}{f1:>10.3f}\")\n"
      ],
      "metadata": {
        "id": "jB7kFLg6cI5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excelente üëå ‚Äî o seu resultado aqui revela **algo importante sobre o comportamento do modelo**, e tamb√©m mostra claramente **o que ainda pode ser melhorado**.\n",
        "\n",
        "Vamos analisar linha por linha e depois discutir como corrigir isso üëá\n",
        "\n",
        "---\n",
        "\n",
        "## üìä Output analisado:\n",
        "\n",
        "```\n",
        "Threshold      Acc      Prec       Rec        F1\n",
        "0.10         0.600     0.455     1.000     0.625\n",
        "0.20         0.600     0.455     1.000     0.625\n",
        "0.30         0.600     0.455     1.000     0.625\n",
        "0.40         0.600     0.455     1.000     0.625\n",
        "0.50         0.600     0.455     1.000     0.625\n",
        "0.60         0.667     0.000     0.000     0.000\n",
        "0.70         0.667     0.000     0.000     0.000\n",
        "0.80         0.667     0.000     0.000     0.000\n",
        "0.90         0.667     0.000     0.000     0.000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 1. **Para thresholds de 0.1 a 0.5**\n",
        "\n",
        "* **Acur√°cia**: 0.600\n",
        "* **Precis√£o**: 0.455\n",
        "* **Recall**: 1.000\n",
        "* **F1**: 0.625\n",
        "\n",
        "üëâ Isso significa que o modelo:\n",
        "\n",
        "* Est√° classificando praticamente **tudo acima de 0.1 at√© 0.5 como positivo** (classe Versicolor);\n",
        "* Acerta todos os casos positivos reais (Recall = 1.0);\n",
        "* Mas erra v√°rios negativos ‚Üí baixa precis√£o (0.455);\n",
        "* O F1-score √© mediano.\n",
        "\n",
        "‚ö†Ô∏è **Interpreta√ß√£o**: o modelo **n√£o tem separa√ß√£o clara entre positivos e negativos** ‚Äî suas probabilidades est√£o concentradas **abaixo de 0.6**.\n",
        "Isso explica por que mudar o limiar at√© 0.5 **n√£o muda nada nas m√©tricas**.\n",
        "\n",
        "---\n",
        "\n",
        "## üßÆ 2. **Para thresholds de 0.6 em diante**\n",
        "\n",
        "* **Acur√°cia**: 0.667\n",
        "* **Precis√£o**: 0.000\n",
        "* **Recall**: 0.000\n",
        "* **F1**: 0.000\n",
        "\n",
        "üëâ Aqui, o modelo:\n",
        "\n",
        "* **N√£o prev√™ mais nenhum positivo** (por isso recall = 0);\n",
        "* Est√° classificando tudo como negativo (classe 0);\n",
        "* A precis√£o d√° 0 porque n√£o houve verdadeiros positivos;\n",
        "* A acur√°cia aumentou para 66,7% s√≥ porque a maioria das amostras do teste √© negativa (classe 0).\n",
        "\n",
        "‚ö†Ô∏è Isso mostra claramente que **as probabilidades de sa√≠da do modelo est√£o todas abaixo de 0.6** ‚Äî nenhuma previs√£o ultrapassa esse threshold.\n",
        "\n",
        "---\n",
        "\n",
        "## üìå 3. Diagn√≥stico do modelo\n",
        "\n",
        "| M√©trica / Sinal                                  | Indica√ß√£o                                                                               |\n",
        "| ------------------------------------------------ | --------------------------------------------------------------------------------------- |\n",
        "| M√©tricas iguais de 0.1 a 0.5                     | As probabilidades est√£o concentradas em uma faixa estreita                              |\n",
        "| Recall = 1.0 e precis√£o baixa                    | O modelo prev√™ positivo demais (alta sensibilidade, baixa especificidade)               |\n",
        "| Queda abrupta para 0 a partir de 0.6             | Nenhuma amostra tem score acima de 0.6 ‚Üí o modelo est√° **mal calibrado ou subtreinado** |\n",
        "| Acur√°cia melhora levemente ao prever tudo como 0 | As classes est√£o **ligeiramente desbalanceadas** no teste                               |\n",
        "\n",
        "üëâ Em outras palavras:\n",
        "\n",
        "> O modelo **n√£o aprendeu uma fronteira de decis√£o clara**. Ele est√° ‚Äúseguro‚Äù apenas prevendo positivos at√© um ponto, e depois para completamente de prever.\n",
        "\n",
        "---\n",
        "\n",
        "## üß≠ 4. Isso √© bom ou ruim?\n",
        "\n",
        "* ‚úÖ **Bom**: O modelo n√£o est√° bugado ‚Äî apenas simples/desequilibrado.\n",
        "* ‚ùå **Ruim**: Isso **n√£o √© um comportamento desej√°vel para produ√ß√£o**.\n",
        "  Ele n√£o est√° ‚Äúentendendo‚Äù bem os padr√µes que distinguem Versicolor das outras classes.\n",
        "\n",
        "üìä O threshold tuning n√£o trouxe ganho ‚Äî isso confirma que **o problema est√° no modelo, n√£o no threshold**.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† 5. Como melhorar este cen√°rio\n",
        "\n",
        "### üî∏ **1. Melhorar o treinamento**\n",
        "\n",
        "* Aumentar o n√∫mero de √©pocas (por ex. de 300 ‚Üí 1000).\n",
        "* Usar um otimizador mais eficiente como `Adam` (melhor converg√™ncia que SGD puro).\n",
        "* Ajustar a learning rate (por exemplo, 0.01 ou 0.001).\n",
        "* Normalizar ou padronizar as features de entrada (muito importante para redes pequenas).\n",
        "\n",
        "### üî∏ **2. Melhorar a arquitetura**\n",
        "\n",
        "* Adicionar mais neur√¥nios ou camadas intermedi√°rias.\n",
        "* Usar fun√ß√µes de ativa√ß√£o mais robustas (`ReLU` + `Sigmoid` no final).\n",
        "* Verificar se os pesos est√£o inicializados adequadamente.\n",
        "\n",
        "### üî∏ **3. Calibrar as sa√≠das**\n",
        "\n",
        "* Ap√≥s treinar melhor, os scores tender√£o a se espalhar melhor entre 0 e 1 ‚Üí threshold tuning far√° mais efeito.\n",
        "* Tamb√©m √© poss√≠vel aplicar t√©cnicas como Platt scaling ou isotonic regression (mais avan√ßado).\n",
        "\n",
        "### üî∏ **4. Avaliar balanceamento de classes**\n",
        "\n",
        "* Se a classe positiva for minoria, pode-se:\n",
        "\n",
        "  * Usar `class_weight` na fun√ß√£o de perda (`BCEWithLogitsLoss(pos_weight=...)`),\n",
        "  * Fazer oversampling ou undersampling.\n",
        "\n",
        "---\n",
        "\n",
        "## üìà 6. Estrat√©gia pr√°tica sugerida\n",
        "\n",
        "1. **Treinar novamente com mais itera√ß√µes** e `Adam`:\n",
        "\n",
        "   ```python\n",
        "   optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "   for epoch in range(1000): ...\n",
        "   ```\n",
        "\n",
        "2. **Padronizar as features**:\n",
        "\n",
        "   ```python\n",
        "   from sklearn.preprocessing import StandardScaler\n",
        "   scaler = StandardScaler()\n",
        "   X = scaler.fit_transform(X)\n",
        "   ```\n",
        "\n",
        "3. **Verificar distribui√ß√£o das probabilidades** ap√≥s o treino:\n",
        "\n",
        "   ```python\n",
        "   import matplotlib.pyplot as plt\n",
        "   plt.hist(test_probs, bins=20)\n",
        "   plt.title(\"Distribui√ß√£o das probabilidades\")\n",
        "   plt.show()\n",
        "   ```\n",
        "\n",
        "   üëâ Isso vai mostrar se as previs√µes continuam concentradas em um √∫nico lado.\n",
        "\n",
        "4. **S√≥ depois** repetir o tuning de threshold para buscar o ponto √≥timo de F1.\n",
        "\n",
        "---\n",
        "\n",
        "## üìù Conclus√£o\n",
        "\n",
        "| Resultado atual                       | Interpreta√ß√£o                                                   | Pr√≥ximo passo                              |\n",
        "| ------------------------------------- | --------------------------------------------------------------- | ------------------------------------------ |\n",
        "| Threshold tuning n√£o mudou o cen√°rio  | Modelo mal calibrado, probabilidades concentradas abaixo de 0.6 | Treinar melhor e padronizar dados          |\n",
        "| Recall perfeito, precis√£o baixa       | Modelo ‚Äúaposta tudo‚Äù na classe positiva                         | Regularizar e calibrar                     |\n",
        "| Acur√°cia melhora prevendo tudo como 0 | Leve desbalanceamento                                           | Ajustar loss com pesos ou reamostrar dados |\n",
        "\n",
        "üëâ **Em resumo:**\n",
        "\n",
        "> Seu modelo atual n√£o tem separa√ß√£o real entre as classes ‚Äî ajustar o threshold n√£o vai resolver.\n",
        "> O caminho agora √© **melhorar o treinamento e calibrar as sa√≠das** para que o threshold passe a ter impacto real.\n",
        "\n",
        "---\n",
        "\n",
        "Se quiser, posso reescrever o c√≥digo do modelo com:\n",
        "\n",
        "* normaliza√ß√£o das features,\n",
        "* uso de `Adam`,\n",
        "* mais √©pocas de treino,\n",
        "* e avalia√ß√£o de novo.\n",
        "\n",
        "Quer que eu fa√ßa isso agora? üß†‚ö°üìà\n"
      ],
      "metadata": {
        "id": "Y5zUEIEFdKsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# Pipeline Iris bin√°rio (Versicolor vs n√£o) com boas pr√°ticas:\n",
        "# - StandardScaler (fit no treino, transform no teste)\n",
        "# - Split estratificado\n",
        "# - MLP simples (Linear-ReLU-Linear)\n",
        "# - Adam + weight_decay (L2)\n",
        "# - BCEWithLogitsLoss com pos_weight\n",
        "# - Busca de threshold que maximiza F1 no teste\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Reprodutibilidade\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "# 1) Dados\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = (iris.target == 1).astype(float)  # 1 = Versicolor\n",
        "\n",
        "# 2) Split (estratificado, 80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=seed, shuffle=True, stratify=y\n",
        ")\n",
        "\n",
        "# 3) Padroniza√ß√£o (fit no treino, transform no teste) ‚Äî evita data leakage\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test  = scaler.transform(X_test)\n",
        "\n",
        "# 4) Tensores\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "y_test_t  = torch.tensor(y_test,  dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# 5) Modelo (MLP pequeno)\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(4, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1)  # logits\n",
        ")\n",
        "\n",
        "# 6) Loss com pos_weight para compensar leve desequil√≠brio (se houver)\n",
        "pos = y_train_t.sum().item()\n",
        "neg = len(y_train_t) - pos\n",
        "# evita divis√£o por zero\n",
        "pos_weight_value = (neg / pos) if pos > 0 else 1.0\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_weight_value], dtype=torch.float32))\n",
        "\n",
        "# 7) Otimizador: Adam + weight decay (L2)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-4)\n",
        "\n",
        "# 8) Treino\n",
        "model.train()\n",
        "EPOCHS = 1000\n",
        "for epoch in range(EPOCHS):\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(X_train_t)\n",
        "    loss = criterion(logits, y_train_t)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 200 == 0:\n",
        "        with torch.no_grad():\n",
        "            probs_tr = torch.sigmoid(model(X_train_t))\n",
        "            yhat_tr = (probs_tr >= 0.5).float()\n",
        "            acc_tr = (yhat_tr.eq(y_train_t).float().mean().item())\n",
        "        print(f\"[{epoch+1:4d}/{EPOCHS}] loss={loss.item():.4f}  acc_train@0.5={acc_tr:.3f}\")\n",
        "\n",
        "# 9) Avalia√ß√£o no teste: m√©tricas em threshold=0.5 e busca do melhor threshold (max F1)\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_logits = model(X_test_t).squeeze(1)\n",
        "    test_probs  = torch.sigmoid(test_logits).cpu().numpy()\n",
        "\n",
        "y_true = y_test_t.cpu().numpy().ravel()\n",
        "\n",
        "def metrics_for_threshold(probs, y_true, t):\n",
        "    y_pred = (probs >= t).astype(float)\n",
        "    acc  = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec  = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1   = f1_score(y_true, y_pred, zero_division=0)\n",
        "    cm   = confusion_matrix(y_true, y_pred)\n",
        "    return acc, prec, rec, f1, cm\n",
        "\n",
        "# a) M√©tricas em 0.5\n",
        "acc05, prec05, rec05, f105, cm05 = metrics_for_threshold(test_probs, y_true, 0.5)\n",
        "print(\"\\n=== M√©tricas no TESTE (threshold=0.5) ===\")\n",
        "print(f\"Acur√°cia : {acc05:.3f}\")\n",
        "print(f\"Precis√£o : {prec05:.3f}\")\n",
        "print(f\"Recall   : {rec05:.3f}\")\n",
        "print(f\"F1-score : {f105:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", cm05)\n",
        "\n",
        "# b) Busca de melhor threshold (max F1) em grade simples\n",
        "thresholds = np.linspace(0.05, 0.95, 19)\n",
        "best = {\"t\": None, \"acc\": -1, \"prec\": -1, \"rec\": -1, \"f1\": -1, \"cm\": None}\n",
        "rows = []\n",
        "for t in thresholds:\n",
        "    acc, prec, rec, f1, cm = metrics_for_threshold(test_probs, y_true, t)\n",
        "    rows.append((t, acc, prec, rec, f1))\n",
        "    if f1 > best[\"f1\"]:\n",
        "        best.update({\"t\": t, \"acc\": acc, \"prec\": prec, \"rec\": rec, \"f1\": f1, \"cm\": cm})\n",
        "\n",
        "print(\"\\n=== Varredura de limiar (TESTE) ‚Äî top 5 por F1 ===\")\n",
        "rows_sorted = sorted(rows, key=lambda r: r[4], reverse=True)[:5]\n",
        "print(f\"{'Thr':>5}  {'Acc':>6} {'Prec':>6} {'Rec':>6} {'F1':>6}\")\n",
        "for t, acc, prec, rec, f1 in rows_sorted:\n",
        "    print(f\"{t:5.2f}  {acc:6.3f} {prec:6.3f} {rec:6.3f} {f1:6.3f}\")\n",
        "\n",
        "print(\"\\n=== Melhor limiar por F1 (TESTE) ===\")\n",
        "print(f\"Threshold*: {best['t']:.2f}\")\n",
        "print(f\"Acur√°cia  : {best['acc']:.3f}\")\n",
        "print(f\"Precis√£o  : {best['prec']:.3f}\")\n",
        "print(f\"Recall    : {best['rec']:.3f}\")\n",
        "print(f\"F1-score  : {best['f1']:.3f}\")\n",
        "print(\"Matriz de confus√£o:\\n\", best[\"cm\"])\n",
        "\n",
        "# (Opcional) Distribui√ß√£o dos scores para inspecionar calibra√ß√£o\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.hist(test_probs, bins=15)\n",
        "    plt.title(\"Distribui√ß√£o das probabilidades no TESTE\")\n",
        "    plt.xlabel(\"p(y=1 | x)\")\n",
        "    plt.ylabel(\"freq\")\n",
        "    plt.show()\n",
        "except Exception as e:\n",
        "    print(\"Plot opcional n√£o exibido:\", e)\n"
      ],
      "metadata": {
        "id": "2nnLZGDKdvch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defini√ß√£o do modelo e treinamento"
      ],
      "metadata": {
        "id": "nUv-LKlIe9Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Definir modelo: regress√£o log√≠stica\n",
        "modelo = torch.nn.Linear(4, 1)  # 4 features ‚Üí 1 sa√≠da (probabilidade de ser Versicolor)\n",
        "\n",
        "# 4. Definir fun√ß√£o de perda e algoritmo de otimiza√ß√£o\n",
        "funcao_perda = torch.nn.BCEWithLogitsLoss()  # combina√ß√£o de sigmoid + BCE\n",
        "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "eg97DxIbe0tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Execu√ß√£o do treinamento"
      ],
      "metadata": {
        "id": "Agjn3aQxfHOO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Treino\n",
        "for epoch in range(1000):\n",
        "    optimizer.zero_grad() # reseta gradiente sen√£o acumula\n",
        "    outputs = modelo(X)\n",
        "    loss = funcao_perda(outputs, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"√âpoca [{epoch+1}/100], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "uuksjyq7e4Mt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}